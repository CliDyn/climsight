"""
Data analysis agent for Climsight.

This agent mirrors PangaeaGPT's oceanographer/visualization style while operating
on local climatology. It filters context, then uses tools to extract or analyze
climate data, saving outputs into the sandbox.
"""

import json
import logging
import os
from typing import Any, Dict, List

from climsight_classes import AgentState

try:
    from utils import make_json_serializable
except ImportError:
    from .utils import make_json_serializable
from sandbox_utils import ensure_thread_id, ensure_sandbox_dirs, get_sandbox_paths
from agent_helpers import create_standard_agent_executor
from tools.era5_retrieval_tool import create_era5_retrieval_tool
from tools.python_repl import CustomPythonREPLTool
from tools.image_viewer import create_image_viewer_tool
from tools.reflection_tools import reflect_tool
from tools.visualization_tools import (
    list_plotting_data_files_tool,
    wise_agent_tool,
)

from langchain_core.prompts import ChatPromptTemplate

logger = logging.getLogger(__name__)


def _build_climate_data_summary(df_list: List[Dict[str, Any]]) -> str:
    """Summarize available climatology without exposing raw values."""
    if not df_list:
        return "No climatology data available."

    lines = []
    for entry in df_list:
        vars_summary = []
        for var_name, var_info in entry.get("extracted_vars", {}).items():
            full_name = var_info.get("full_name", var_name)
            units = var_info.get("units", "")
            vars_summary.append(f"{full_name} ({units})")
        vars_text = ", ".join(vars_summary) if vars_summary else "Unknown variables"
        lines.append(
            f"- {entry.get('years_of_averaging', '')}: {entry.get('description', '')} | {vars_text}"
        )

    return "\n".join(lines)


def _build_datasets_text(state) -> str:
    """Build simple dataset paths text for prompt injection.

    IMPORTANT: The Python REPL kernel CWD is already set to the sandbox root,
    so we tell the agent to use RELATIVE paths (not full tmp/sandbox/... paths).
    """
    lines = [
        "## Sandbox Paths (Python REPL is ALREADY inside the sandbox directory)",
        "**CRITICAL: Use RELATIVE paths in your Python code, NOT full paths starting with 'tmp/sandbox/...'**",
        f"- Current Working Directory: '.' (which is {state.uuid_main_dir})",
        f"- Results directory: 'results' (save all plots here)",
        f"- Climate data: 'climate_data'",
    ]

    if state.era5_data_dir:
        lines.append(f"- ERA5 data: 'era5_data'")

    # List available climate data files
    if state.climate_data_dir and os.path.exists(state.climate_data_dir):
        try:
            files = os.listdir(state.climate_data_dir)
            if files:
                lines.append(f"\n## Climate Data Files Available (in 'climate_data/' folder)")
                lines.append(f"Files: {', '.join(files)}")
                # Highlight the main data.csv file
                if "data.csv" in files:
                    lines.append("Note: Load with `pd.read_csv('climate_data/data.csv')`")
        except Exception as e:
            logger.warning(f"Could not list climate data files: {e}")

    return "\n".join(lines)


def _build_filter_prompt() -> str:
    """Prompt for the analysis brief filter LLM."""
    return (
        "You are a data analysis filter for a climate assistant.\n"
        "Extract only actionable analysis requirements.\n\n"
        "Output format (bullets only):\n"
        "- Target variables (with units if specified)\n"
        "- Thresholds or criteria\n"
        "- Time ranges or scenarios\n"
        "- Spatial specifics (location, buffers)\n"
        "- Analysis tasks (comparisons, trends, plots)\n\n"
        "Rules:\n"
        "- Do NOT include raw climate data values.\n"
        "- Do NOT include long RAG or Wikipedia text.\n"
        "- Omit vague statements that are not actionable.\n"
    )


def _create_tool_prompt(datasets_text: str, config: dict, lat: float = None, lon: float = None,
                        has_climate_data: bool = False, has_hazard_data: bool = False,
                        has_population_data: bool = False, has_era5_data: bool = False) -> str:
    """System prompt for tool-driven analysis - dynamically built based on config.

    NOTE: This agent only runs when python_REPL is enabled (use_powerful_data_analysis=True).
    ERA5 climatology and predefined plots are already generated by prepare_predefined_data.
    """
    has_era5_download = config.get("use_era5_data", False)
    # This agent only runs when python_REPL is enabled (conditional routing)
    has_repl = True

    prompt = """You are the data analysis agent for ClimSight.
Your job is to provide ADDITIONAL quantitative climate analysis with custom visualizations.

## PRE-EXTRACTED DATA (ALREADY AVAILABLE - DO NOT RE-EXTRACT)

The following data has ALREADY been extracted and saved to the sandbox:
"""

    if has_era5_data:
        prompt += """
- **ERA5 Climatology** (GROUND TRUTH observations):
  - File: `era5_climatology.json` in sandbox root
  - Contains: temperature (t2m), precipitation (tp), wind (u10, v10) - monthly averages
  - Period: 2015-2025 climatology
  - Load with: `era5 = json.load(open('era5_climatology.json'))`
  - DO NOT call any ERA5 extraction tool - data is already available!
"""

    if has_climate_data:
        prompt += """
- **Climate Model Data**:
  - File: `climate_data/data.csv` and `climate_data/climate_data_manifest.json`
  - Contains: temperature, precipitation, wind - historical and future projections
  - Load with: `df = pd.read_csv('climate_data/data.csv')`
"""

    prompt += """
## PRE-GENERATED PLOTS (ALREADY CREATED - DO NOT RECREATE)

The following standard visualizations have ALREADY been generated and saved to results/:
"""

    if has_climate_data:
        prompt += """
- **Climate comparison plots**: results/climate_*.png
  - Temperature, precipitation, wind comparison with ERA5 observations (black line)
  - DO NOT recreate these with Python_REPL - they already exist!
"""

    if has_hazard_data:
        prompt += """
- **Disaster summary**: results/disaster_counts.png
  - Historical disaster events by type for the location
"""

    if has_population_data:
        prompt += """
- **Population projection**: results/population_projection.png
  - Population trends for the location's country
"""

    prompt += """
**IMPORTANT**: Analyze the pre-extracted DATA directly instead of using image_viewer on predefined plots.
Only use image_viewer for plots YOU create with Python_REPL.

## AVAILABLE TOOLS
"""
    tool_num = 1

    # ERA5 time series download (optional, for detailed year-by-year analysis)
    if has_era5_download:
        prompt += f"""
{tool_num}. **retrieve_era5_data** - **IMPORTANT: Download ERA5 time series for detailed analysis**
   <Important>
   **CALL THIS TOOL** to get year-by-year climate data (2015-2024) for robust analysis.
   The pre-extracted ERA5 climatology only has 10-year averages - this tool gives you FULL TIME SERIES!

   **DATA SOURCE:** Earthmover (Arraylake), hardcoded to "temporal" mode.
   **VARIABLE CODES:** Use short codes: 't2' (Temp), 'u10'/'v10' (Wind), 'mslp' (Pressure), 'tp' (Precip).
   **WORK_DIR:** Pass work_dir='.' to save in current sandbox.

   **OUTPUT & LOADING:**
   The tool returns an absolute path to a Zarr store (saved in 'era5_data/' folder).
   **CRITICAL:** In Python_REPL, use RELATIVE paths to load the data since CWD is already the sandbox:

   ```python
   import xarray as xr
   import glob

   # List available ERA5 Zarr files (RELATIVE path)
   era5_files = glob.glob('era5_data/*.zarr')
   print(era5_files)

   # Load using RELATIVE path (NOT the absolute path from tool response)
   ds = xr.open_dataset('era5_data/era5_t2_temporal_....zarr', engine='zarr', chunks={{{{}}}})
   data = ds['t2'].to_series()
   ```
   </Important>
"""
        tool_num += 1

    # TOOL #4: Python REPL
    if has_repl:
        prompt += f"""
{tool_num}. **Python_REPL** - Execute Python code for data analysis and visualizations
   - Pre-loaded: pandas (pd), numpy (np), matplotlib.pyplot (plt), xarray (xr)
   - Working directory is ALREADY the sandbox root
   - ALWAYS save plots to results/ directory
   **CRITICAL PATH RULE:**
   ❌ WRONG: `base='tmp/sandbox/uuid...'` then `f'{{{{base}}}}/era5_data/...'`
   ✓ CORRECT: Use relative paths directly: `'era5_data/...'`, `'climate_data/...'`, `'results/...'`
   The kernel CWD is already inside the sandbox, so DO NOT prepend 'tmp/sandbox/...'!

   **Climate Model Data** (climate_data/ directory):
   - `climate_data_manifest.json` - READ THIS FIRST to see all available simulations
   - `simulation_1.csv`, `simulation_2.csv`, ... - Data for different time periods
   - `simulation_N_meta.json` - Metadata (years, description) for each simulation
   - `data.csv` - Main/baseline simulation only (for quick access)
   - Columns: Month, mean2t (temperature °C), tp (precipitation mm/month), wind_u, wind_v, wind_speed, wind_direction
   - Use list_plotting_data_files tool to discover all available files

   **ERA5 Climatology** (era5_climatology.json):
   - After calling get_era5_climatology, results are saved here
   - Load with: `import json; era5 = json.load(open('era5_climatology.json'))`
   - Use ERA5 as GROUND TRUTH baseline for comparisons

   Example workflow:
   ```python
   import pandas as pd
   import json
   import matplotlib.pyplot as plt

   # 1. Load manifest to see all available simulations
   manifest = json.load(open('climate_data/climate_data_manifest.json'))
   print(f"Data source: {{{{manifest['source']}}}}")
   for entry in manifest['entries']:
       print(f"  {{{{entry['csv']}}}} : {{{{entry['years_of_averaging']}}}}")

   # 2. Load ERA5 observations (ground truth)
   era5 = json.load(open('era5_climatology.json'))
   era5_temp = era5['variables']['t2m']['monthly_values']

   # 3. Load multiple climate model simulations
   simulations = []
   for entry in manifest['entries']:
       df = pd.read_csv(f"climate_data/{{{{entry['csv']}}}}")
       simulations.append({{{{'df': df, 'years': entry['years_of_averaging'], 'main': entry['main']}}}}))

   # 4. Plot comparison
   months = list(era5_temp.keys())
   plt.figure(figsize=(12, 6))
   plt.plot(months, list(era5_temp.values()), 'k-o', linewidth=2, label='ERA5 Observations')
   for sim in simulations:
       style = '-' if sim['main'] else '--'
       plt.plot(months, sim['df']['mean2t'].tolist(), style, label=f"Model {{{{sim['years']}}}}")
   plt.xlabel('Month')
   plt.ylabel('Temperature (°C)')
   plt.legend()
   plt.tight_layout()
   plt.savefig('results/temperature_comparison.png', dpi=150)
   plt.close()
   ```
"""
        tool_num += 1

    prompt += f"""
{tool_num}. **list_plotting_data_files** - List files in sandbox directories
"""
    tool_num += 1

    # image_viewer is ALWAYS available (works with predefined plots and Python REPL plots)
    prompt += f"""
{tool_num}. **image_viewer** - View and analyze generated plots
   <Important>
   Use this to verify any visualization in results/ folder.
   Works with both predefined plots and Python_REPL generated plots.
   Pass relative paths like 'results/climate_temperature.png' or 'climate_temperature.png'
   </Important>
"""
    tool_num += 1

    # reflect_on_image and wise_agent only available with Python REPL
    if has_repl:
        prompt += f"""{tool_num}. **reflect_on_image** - Analyze a generated plot and get feedback for improvements
{tool_num + 1}. **wise_agent** - Get guidance on complex visualization decisions
"""
        tool_num += 2

    prompt += """
## REQUIRED WORKFLOW

**All standard data and plots are ALREADY prepared. Your job is ADDITIONAL analysis.**

**STEP 1 - LOAD PRE-EXTRACTED DATA:**
```python
import pandas as pd
import json

# Load ERA5 observations (ground truth - ALREADY EXTRACTED)
era5 = json.load(open('era5_climatology.json'))
era5_temp = era5['variables']['t2m']['monthly_values']
era5_precip = era5['variables']['tp']['monthly_values']

# Load climate model data (ALREADY EXTRACTED)
df = pd.read_csv('climate_data/data.csv')
```
"""

    if has_era5_download:
        prompt += """
**STEP 2 - DOWNLOAD ERA5 TIME SERIES (STRONGLY RECOMMENDED):**
You have access to ERA5 time series data - USE IT! This provides YEAR-BY-YEAR observations that are
essential for robust climate analysis. The pre-extracted climatology only gives you 10-year averages.

**ALWAYS call retrieve_era5_data to get:**
- **Temperature (t2)**: time series - essential for detecting warming trends
- **Precipitation (tp)**: time series - essential for drought/flood analysis

**WHY THIS DATA IS CRITICAL:**
1. **Interannual Variability**: See how much temperature/precipitation varies year-to-year
2. **Trend Detection**: Identify if climate is already changing at this location
3. **Extreme Events**: Find heat waves, droughts, wet years in the historical record
4. **Context for Projections**: Compare model predictions against actual recent trends
5. **Confidence Assessment**: Large interannual variability = less confidence in projections

**Data saved to era5_data/ as .zarr files** - load in Python_REPL for analysis.

DO NOT skip this step - the time series data significantly improves analysis quality!
"""

    # Step numbering depends on whether ERA5 download is available
    if has_era5_download:
        next_step = 3
    else:
        next_step = 2

    prompt += f"""
**STEP {next_step} - PERFORM CUSTOM ANALYSIS:**
Based on the user's query, create ADDITIONAL analysis that goes beyond the standard plots.
Examples:
- Specific month comparisons
- Trend analysis
- Threshold exceedance calculations
- Seasonal patterns
- Model bias quantification

**STEP {next_step + 1} - CREATE ADDITIONAL VISUALIZATIONS:**
Only create plots that provide NEW insights beyond the pre-generated climate comparison plots.
- Save ALL plots to results/ directory
- DO NOT recreate the standard climate_*.png plots
"""

    prompt += f"""
## SANDBOX PATHS AND DATA

{datasets_text}

## PROACTIVE ANALYSIS

Even if the user doesn't explicitly ask for plots, you SHOULD:
- Create temperature trend visualizations
- Show precipitation comparisons
- Highlight months with largest projected changes
- Identify potential climate risks (heat stress, drought, flooding)
"""

    if has_era5_download:
        prompt += """
**ERA5 TIME SERIES ANALYSIS (REQUIRED when ERA5 API is available):**
Since you have access to ERA5 time series data, you MUST:
1. Call **retrieve_era5_data** to get temperature (t2) and precipitation (tp) time series
2. Analyze the trends - is the location changing (warming/drying)?
3. Calculate interannual variability (standard deviation across years)
4. Identify any extreme years (hottest, coldest, wettest, driest)
5. Create a time series plot showing year-by-year values with trend line
6. Compare observed trends with climate model projections

This analysis provides ESSENTIAL context that cannot be obtained from climatology alone!
"""

    if has_era5_data:
        prompt += """
**With ERA5 observations, ALWAYS include:**
- Current observed climate (from ERA5 - this is REALITY)
- Model performance assessment (how well does the model match observations?)
- Future projections interpreted in context of model quality
"""

    prompt += """
## OUTPUT FORMAT

Your final response should include:
"""

    if has_era5_data:
        prompt += """1. **Current Climate (ERA5 Observations)**: What the climate ACTUALLY IS (2015-2025 average)
2. **Model Assessment**: How well climate models match ERA5 observations
3. **Future Projections**: Model predictions with confidence based on model-observation agreement
4. **Climate Change Signal**: Projected changes from current observed baseline
5. **Critical Months**: Which months show largest changes
6. **Visualizations**: List of plot files created
7. **Implications**: Interpretation relevant to the user's query
"""
    else:
        prompt += """1. **Key Climate Values**: Extracted temperature, precipitation data
2. **Climate Change Signal**: Differences between historical and future projections
3. **Critical Months**: Which months show largest changes
4. **Visualizations**: List of plot files created (if Python_REPL available)
5. **Implications**: Brief interpretation relevant to the user's query
"""

    prompt += """
Limit total tool calls to 50.
"""
    return prompt


def _normalize_tool_observation(observation: Any) -> Any:
    """Normalize tool output into a plain Python object."""
    try:
        from langchain_core.messages import AIMessage
    except Exception:
        AIMessage = None

    if AIMessage is not None and isinstance(observation, AIMessage):
        return observation.content
    return observation


def data_analysis_agent(
    state: AgentState,
    config: dict,
    api_key: str,
    api_key_local: str,
    stream_handler,
    llm_dataanalysis_agent=None,
):
    """Run filtered analysis + tool-based climatology extraction."""
    stream_handler.update_progress("Data analysis: preparing sandbox...")

    # Ensure sandbox paths are available.
    thread_id = ensure_thread_id(existing_thread_id=state.thread_id)
    sandbox_paths = get_sandbox_paths(thread_id)
    ensure_sandbox_dirs(sandbox_paths)

    state.thread_id = thread_id
    state.uuid_main_dir = sandbox_paths["uuid_main_dir"]
    state.results_dir = sandbox_paths["results_dir"]
    state.climate_data_dir = sandbox_paths["climate_data_dir"]
    state.era5_data_dir = sandbox_paths["era5_data_dir"]

    # Build analysis context for filtering.
    climate_summary = _build_climate_data_summary(state.df_list)
    context_sections = [
        f"User query: {state.user}",
        f"Location: {state.input_params.get('location_str', '')}",
        f"Coordinates: {state.input_params.get('lat', '')}, {state.input_params.get('lon', '')}",
        f"Climatology summary:\n{climate_summary}",
    ]

    if state.ipcc_rag_agent_response:
        context_sections.append(f"IPCC RAG: {state.ipcc_rag_agent_response}")
    if state.general_rag_agent_response:
        context_sections.append(f"General RAG: {state.general_rag_agent_response}")
    if state.smart_agent_response:
        context_sections.append(f"Smart agent: {state.smart_agent_response.get('output', '')}")
    if state.ecocrop_search_response:
        context_sections.append(f"ECOCROP: {state.ecocrop_search_response}")
    if state.zero_agent_response:
        safe_zero_context = make_json_serializable(state.zero_agent_response)
        context_sections.append(f"Local context: {json.dumps(safe_zero_context, indent=2)}")

    analysis_context = "\n\n".join(context_sections)

    # Check if filter step is enabled (configurable)
    use_filter_step = config.get("llm_dataanalysis", {}).get("use_filter_step", True)

    if use_filter_step and llm_dataanalysis_agent is not None:
        stream_handler.update_progress("Data analysis: filtering context...")
        filter_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", _build_filter_prompt()),
                ("user", "{context}"),
            ]
        )
        result = llm_dataanalysis_agent.invoke(filter_prompt.format_messages(context=analysis_context))
        filtered_context = result.content if hasattr(result, "content") else str(result)

        # CRITICAL: Always preserve the user's original question
        location_str = state.input_params.get('location_str', 'Unknown location')
        analysis_brief = f"""USER QUESTION: {state.user}

Location: {location_str}
Coordinates: {state.input_params.get('lat', '')}, {state.input_params.get('lon', '')}

ANALYSIS REQUIREMENTS:
{filtered_context}
"""
    else:
        # Skip filter step - pass essential context directly
        stream_handler.update_progress("Data analysis: preparing context (no filter)...")
        location_str = state.input_params.get('location_str', 'Unknown location')
        analysis_brief = f"""USER QUESTION: {state.user}

Location: {location_str}
Coordinates: {state.input_params.get('lat', '')}, {state.input_params.get('lon', '')}

Available climatology:
{climate_summary}

Required analysis:
- Extract Temperature and Precipitation data
- Compare historical vs future projections
- Create visualizations if Python_REPL is available
"""

    state.data_analysis_prompt_text = analysis_brief

    brief_path = os.path.join(state.uuid_main_dir, "analysis_brief.txt")
    with open(brief_path, "w", encoding="utf-8") as f:
        f.write(analysis_brief)

    # Build simplified datasets_text for prompt
    datasets_text = _build_datasets_text(state)

    # Build datasets dict for Python REPL
    datasets = {
        "uuid_main_dir": state.uuid_main_dir,
        "results_dir": state.results_dir,
    }
    if state.climate_data_dir:
        datasets["climate_data_dir"] = state.climate_data_dir
    if state.era5_data_dir:
        datasets["era5_data_dir"] = state.era5_data_dir

    # Get coordinates for prompt
    lat = state.input_params.get('lat')
    lon = state.input_params.get('lon')
    try:
        lat = float(lat) if lat is not None else None
        lon = float(lon) if lon is not None else None
    except (ValueError, TypeError):
        lat, lon = None, None

    # Tool setup for data_analysis_agent
    # NOTE: This agent only runs when python_REPL is enabled (use_powerful_data_analysis=True)
    # ERA5 climatology and predefined plots are already generated by prepare_predefined_data
    tools = []

    has_era5_data = config.get("era5_climatology", {}).get("enabled", True)
    # This agent only runs when use_powerful_data_analysis=True, so Python REPL is always available
    has_python_repl = True

    # NOTE: ERA5 climatology and predefined plots are ALREADY generated by prepare_predefined_data
    # The agent should use the pre-extracted data, not re-extract it
    logger.info(f"data_analysis_agent starting - predefined plots: {state.predefined_plots}")
    logger.info(f"ERA5 climatology available: {bool(state.era5_climatology_response)}")

    # 3. ERA5 time series retrieval (if enabled - for detailed year-by-year analysis)
    if config.get("use_era5_data", False):
        arraylake_api_key = config.get("arraylake_api_key", "")
        if arraylake_api_key:
            tools.append(create_era5_retrieval_tool(arraylake_api_key))
        else:
            logger.warning("ERA5 data enabled but no arraylake_api_key in config. ERA5 retrieval tool not added.")

    # 4. Python REPL for analysis/visualization (if enabled)
    if has_python_repl:
        repl_tool = CustomPythonREPLTool(
            datasets=datasets,
            results_dir=state.results_dir,
            session_key=thread_id,
        )
        tools.append(repl_tool)

    # 5. Helper tools
    tools.append(list_plotting_data_files_tool)

    # 6. Image viewer - ALWAYS available (plots are saved to results/ folder)
    #    Works with predefined plots even when Python REPL is disabled
    vision_model = config.get("llm_combine", {}).get("model_name", "gpt-4o")
    image_viewer_tool = create_image_viewer_tool(
        openai_api_key=api_key,
        model_name=vision_model,
        sandbox_path=state.results_dir  # Point to results folder where plots are saved
    )
    tools.append(image_viewer_tool)

    # 7. Image reflection and wise_agent - ONLY when Python REPL is enabled
    #    (these tools are for evaluating/creating visualizations)
    if has_python_repl:
        tools.append(reflect_tool)
        tools.append(wise_agent_tool)

    stream_handler.update_progress("Data analysis: running tools...")
    tool_prompt = _create_tool_prompt(
        datasets_text, config, lat=lat, lon=lon,
        has_climate_data=bool(state.df_list),
        has_hazard_data=state.hazard_data is not None,
        has_population_data=bool(state.population_config),
        has_era5_data=bool(state.era5_climatology_response)
    )

    if llm_dataanalysis_agent is None:
        from langchain_openai import ChatOpenAI

        llm_dataanalysis_agent = ChatOpenAI(
            openai_api_key=api_key,
            model_name=config.get("llm_combine", {}).get("model_name", "gpt-4.1-nano"),
        )

    agent_executor = create_standard_agent_executor(
        llm_dataanalysis_agent,
        tools,
        tool_prompt,
        max_iterations=20,
    )

    agent_input = {
        "input": analysis_brief or state.user,
        "messages": state.messages,
    }

    result = agent_executor(agent_input)

    data_components_outputs = []
    plot_images: List[str] = []
    era5_climatology_output = None
    agent_references: List[str] = []  # Collect references from agent tools

    for action, observation in result.get("intermediate_steps", []):
        if action.tool == "get_era5_climatology":
            obs = _normalize_tool_observation(observation)
            if isinstance(obs, dict) and "error" not in obs:
                era5_climatology_output = obs
                state.era5_climatology_response = obs
                # Collect reference from ERA5 climatology
                if "reference" in obs:
                    agent_references.append(obs["reference"])
        if action.tool == "get_data_components":
            obs = _normalize_tool_observation(observation)
            data_components_outputs.append(obs)
            # Collect references from get_data_components
            if isinstance(obs, dict):
                if "reference" in obs:
                    agent_references.append(obs["reference"])
                if "references" in obs:
                    agent_references.extend(obs["references"])
        if action.tool in ("Python_REPL", "python_repl"):
            obs = _normalize_tool_observation(observation)
            if isinstance(obs, dict):
                plot_images.extend(obs.get("plot_images", []))
        if action.tool == "retrieve_era5_data":
            # Handle ERA5 retrieval tool output
            obs = _normalize_tool_observation(observation)
            if isinstance(obs, dict):
                era5_output = str(obs)
                # Collect reference from ERA5 retrieval
                if "reference" in obs:
                    agent_references.append(obs["reference"])
            elif hasattr(obs, 'content'):
                era5_output = obs.content
            else:
                era5_output = str(obs)
            # Store in state
            state.era5_tool_response = era5_output
            state.input_params.setdefault("era5_results", []).append(obs)

    # Add agent-collected references to state.references (deduplicate)
    for ref in agent_references:
        if ref and ref not in state.references:
            state.references.append(ref)

    analysis_text = result.get("output", "")

    # Append ERA5 climatology summary if available
    if era5_climatology_output:
        analysis_text += "\n\n### ERA5 Observational Baseline (2015-2025)\n"
        analysis_text += f"Location: {era5_climatology_output.get('extracted_location', {})}\n"
        if "variables" in era5_climatology_output:
            for var_name, var_data in era5_climatology_output["variables"].items():
                analysis_text += f"\n**{var_data.get('full_name', var_name)}** ({var_data.get('units', '')}):\n"
                monthly = var_data.get("monthly_values", {})
                # Show a few key months
                for month in ["January", "April", "July", "October"]:
                    if month in monthly:
                        analysis_text += f"  {month}: {monthly[month]}\n"

    if data_components_outputs:
        analysis_text += "\n\n### Climate Model Extracts:\n"
        for item in data_components_outputs:
            analysis_text += json.dumps(item, indent=2) + "\n"

    # Combine all plot images (pre-generated + agent-generated)
    all_plot_images = state.predefined_plots + plot_images

    state.data_analysis_response = analysis_text
    state.data_analysis_images = all_plot_images

    stream_handler.update_progress("Data analysis complete.")

    return {
        "data_analysis_response": analysis_text,
        "data_analysis_images": all_plot_images,
        "predefined_plots": state.predefined_plots,
        "data_analysis_prompt_text": analysis_brief,
        "era5_climatology_response": state.era5_climatology_response,
        "era5_tool_response": getattr(state, 'era5_tool_response', None),
        "references": state.references,  # Propagate collected references
    }
