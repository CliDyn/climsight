save.py
code
import os
import sys

def save_code_to_txt(root_dir, output_file):
    try:
        with open(output_file, 'w') as f:
            for dirpath, dirnames, filenames in os.walk(root_dir):
                # Skip 'venv' directories and hidden directories
                dirnames[:] = [d for d in dirnames if d != 'venv' and not d.startswith('.')]
                for filename in filenames:
                    if filename.endswith('.py'):
                        file_path = os.path.join(dirpath, filename)
                        relative_path = os.path.relpath(file_path, root_dir)

                        # Write the relative path of the file
                        f.write(f"{relative_path}\n")
                        f.write("code\n")

                        try:
                            # Write the content of the file
                            with open(file_path, 'r', encoding='utf-8') as code_file:
                                f.write(code_file.read())
                        except Exception as e:
                            print(f"Error reading file {file_path}: {str(e)}")
                            continue

                        f.write("\n" + "-" * 80 + "\n")
    except Exception as e:
        print(f"Error saving code to file: {str(e)}")
        sys.exit(1)

if __name__ == "__main__":
    # Get the absolute path of the project root
    project_root = '/Users/dmpantiu/PycharmProjects/hackathon_hamburg/climsight'
    
    # Verify the directory exists
    if not os.path.exists(project_root):
        print(f"Error: Directory {project_root} does not exist")
        sys.exit(1)

    # Create output file path
    output_file = os.path.join(project_root, 'project_structure.txt')

    print(f"Scanning directory: {project_root}")
    save_code_to_txt(project_root, output_file)
    print(f"Project structure and code saved to {output_file}")

--------------------------------------------------------------------------------
download_data.py
code
import requests
import tarfile
import zipfile
import os
import shutil
import sys
import yaml 
import argparse

def download_file(url, local_filename):
    """Attempt to download a file from a URL and save it locally, with a progress indicator."""
    try:
        with requests.get(url, stream=True) as r:
            r.raise_for_status()
            # Get total file size from headers, if available
            total_length = r.headers.get('content-length')
            if total_length is not None:
                total_length = int(total_length)
                downloaded = 0

            with open(local_filename, 'wb') as f:
                for chunk in r.iter_content(chunk_size=8192):
                    f.write(chunk)
                    if total_length is not None:
                        downloaded += len(chunk)
                        # Calculate the percentage of the file downloaded and update the progress bar
                        done_percentage = int(100 * downloaded / total_length)
                        # Update the progress bar
                        sys.stdout.write(f"\rDownloading {local_filename}: {done_percentage}%")
                        sys.stdout.flush()
            if total_length is not None:
                sys.stdout.write('\n')  # Move the cursor to the next line after download completes

        return True
    except requests.RequestException as e:
        print(f"\033[93mWarning: Failed to download {url}. Please download manually.\033[0m")
        print(f"\033[91mError: {e}\033[0m")
        return False


def extract_tar(file_path, extract_to='.'):
    """Extract tar file and handle errors."""
    try:
        with tarfile.open(file_path) as tar:
            tar.extractall(path=extract_to)
        os.remove(file_path)
    except Exception as e:
        print(f"\033[93mWarning: Failed to extract {file_path}.\033[0m")

def extract_zip(file_path, extract_to='.'):
    """Extract zip file and handle errors."""
    try:
        with zipfile.ZipFile(file_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
        os.remove(file_path)
    except Exception as e:
        print(f"\033[93mWarning: Failed to extract {file_path}.\033[0m")

def extract_arch(file_path, extract_to='.', archive_type=''):
    """Extract tar/zip file and handle errors.
        if archive_type='' (default) file will be moved
    """
    if not archive_type:
        _, file_extension = os.path.splitext(file_path)
        if file_extension in ['.zip']:
            archive_type = 'zip'
        elif file_extension in ['.tar']:
            archive_type = 'tar'
    try:
        if archive_type=='zip':
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                zip_ref.extractall(extract_to)
        elif archive_type=='tar':
            with tarfile.open(file_path) as tar:
                tar.extractall(path=extract_to)
        else:
            #cp file to     
            destination_file = os.path.join(extract_to, os.path.basename(file_path))   
            shutil.copyfile(file_path,destination_file)    
        os.remove(file_path)
    except Exception as e:
        print(f"\033[93mWarning: Failed to extract {file_path}.\033[0m")        

def create_dir(path):
    """Create a directory if it doesn't exist."""
    os.makedirs(path, exist_ok=True)

def remove_dir(path):
    """Remove a directory if it exists."""
    if os.path.exists(path) and os.path.isdir(path):
        shutil.rmtree(path)

def main():
    # Parse command-line argument (--source_files)
    parser = argparse.ArgumentParser(description="Download and extract the raw source files of the RAG.")
    parser.add_argument('--source_files', type=bool, default=False, help='Whether to download and extract source files (IPCC text reports).')
    args = parser.parse_args()

    # Load the YAML file
    with open('data_sources.yml', 'r') as file:
        data_config = yaml.safe_load(file)

    base_path = data_config['base_path']
    sources = data_config['sources']

    #make subdirs list and clean it
    subdirs = []
    for entry in sources:
        subdirs.append(entry['subdir'])
    subdirs = set(subdirs)
    subdirs = list(subdirs)
    subdirs = [folder for folder in subdirs if folder not in ['.', './']]

    for subdir in subdirs:
        create_dir(os.path.join(base_path, subdir))

    # Download and extract files
    
    files_downloaded = []
    files_skiped = []
    urls_skiped = []
    subdirs_skiped = []

    for entry in sources:
        file = entry['filename']
        url  = entry['url']
        subdir = os.path.join(base_path, entry['subdir'])

        # Skip downloading source files of RAG unless --source_files is set to True
        if file == 'ipcc_text_reports.zip' and not args.source_files:
            print("Skipping IPCC text report download as --source_files flag is not set or False.")
            continue

        if download_file(url, file):
            extract_arch(file, subdir)
            files_downloaded.append(file)        
        else:
            files_skiped.append(file)
            urls_skiped.append(url)
            subdirs_skiped.append(subdir)
 
    if (files_skiped):
        print('\n')                      
        print('----------------------------------------------')                      
        print(f"\033[91mFiles not downloaded, please download manualy:\033[0m")
        for i,file in enumerate(files_skiped):
            print('--------')               
            print(f"\033[93mFile:\033[0m", file)
            print(f"\033[93mUrl:\033[0m", urls_skiped[i])        
            print(f"\033[93munpack it into the:\033[0m ", subdirs_skiped[i])            
            print('--------')        

    # I would leave it for a while
    #print('\n')                      
    #print('----------------------------------------------')                      
    #print("You also need to download the natural hazard data (for which you have to create a free account). Please download the CSV - Disaster Location Centroids [zip file] and unpack it into the 'data/natural_hazards' folder. Your file should automatically be called 'pend-gdis-1960-2018-disasterlocations.csv'. If not, please change the file name accordingly.")
    #print(f"\033[93mhttps://sedac.ciesin.columbia.edu/data/set/pend-gdis-1960-2018/data-download\033[0m")
    #print('-------------------')                      
    
if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
test/test_environmental_functions.py
code
'''
This script performs unit testing for the climsight 
   environmenatl
            functions,
ensuring configuration files are correctly loaded ...
It uses pytest to test 
The tests validate both the 
presence of essential config files and the accuracy of data fetched from 
external geocoding services. 
'''

import pytest
import yaml
import warnings
import sys
import os
import requests
import requests_mock
import pandas as pd
import matplotlib.pyplot as plt

# Append the directory containing the module to sys.path
module_dir = os.path.abspath('../src/climsight/')
if module_dir not in sys.path:
    sys.path.append(module_dir)


from environmental_functions import (
   fetch_biodiversity,
   load_nat_haz_data,
   filter_events_within_square,
   plot_disaster_counts
)

config_path = '../config.yml'
test_config_path = 'config_test_environmental_functions.yml'

def test_config_files_exist():
    assert os.path.exists(config_path), f"Configuration file does not exist: {config_path}"
    assert os.path.exists(test_config_path), f"Test configuration file does not exist: {test_config_path}"


@pytest.fixture
def config_main():
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

#config = config_main


@pytest.fixture
def config_test():
    with open(test_config_path, 'r') as file:
        config_data = yaml.safe_load(file)
    return config_data

#config_test = config_data

@pytest.fixture
def latlon(config_test):
    lat = float(config_test['test_location']['lat'])
    lon = float(config_test['test_location']['lon'])
    return lat, lon  
 
 #----------------------------- Test biodiversity
@pytest.fixture
def expected_biodiv(config_test):
    return config_test['test_location']['biodiv']

@pytest.mark.request 
@pytest.mark.env
def test_fetch_biodiversity(config_test, expected_biodiv):
    lat, lon = config_test['test_location']['lat'], config_test['test_location']['lon']
    biodiv = fetch_biodiversity(round(lat), round(lon))
    assert biodiv == expected_biodiv, f"error in fetch_biodiversity, point({lat},{lon})"

#test with mock request 
@pytest.mark.mock_request
@pytest.mark.env
def test_mock_fetch_biodiversity(config_test, expected_biodiv, requests_mock):
    lat, lon = config_test['test_location']['lat'], config_test['test_location']['lon']
    
    mock_url = "https://api.gbif.org/v1/occurrence/search"
    mock_response = config_test['expected_biodiv']

    requests_mock.get(mock_url, json=mock_response)

    biodiv = fetch_biodiversity(round(lat), round(lon))
    assert biodiv == expected_biodiv, f"error in fetch_biodiversity, point({lat},{lon})"    
    
 #----------------------------- Test filter_events_within_square
def are_dataframes_equal(df1, df2, tol=1e-6):
    """
    Compares two DataFrames for equality within a specified tolerance level.
    Returns True if they are equal within the tolerance, otherwise False.
    """
    try:
        pd.testing.assert_frame_equal(df1, df2, check_dtype=False, atol=tol)
        return True
    except AssertionError:
        return False

@pytest.mark.hazard
@pytest.mark.env
@pytest.mark.local_data    
def test_filter_events_within_square(config_test, config_main, expected_biodiv):
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('..')   
    
    haz_path = config_main['haz_path']
    distance_from_event = config_main['distance_from_event']
    lat, lon = config_test['test_location']['lat'], config_test['test_location']['lon']
    try:
        filtered_events_square, promt_hazard_data = filter_events_within_square(lat, lon, haz_path, distance_from_event)
    except Exception as e:
        warnings.warn(f"Failed to filter_events_within_square: {str(e)}", RuntimeWarning)
        # Explicitly fail the test with a message
        pytest.fail(f"Test failed due to an error in filter_events_within_square: {str(e)}, no files in data ?")        
            
    expected_promt_hazard_data = pd.DataFrame(config_test['test_location']['promt_hazard_data'])    
    expected_filtered_events_square = pd.DataFrame(config_test['test_location']['filtered_events_square'])    
    expected_filtered_events_square['latitude'] = pd.to_numeric(expected_filtered_events_square['latitude'], errors='coerce')
    expected_filtered_events_square['longitude'] = pd.to_numeric(expected_filtered_events_square['longitude'], errors='coerce')

    promt_hazard_data = promt_hazard_data.reset_index(drop=True)
    filtered_events_square = filtered_events_square.reset_index(drop=True)
    
    assert promt_hazard_data.equals(expected_promt_hazard_data)
    assert are_dataframes_equal(expected_filtered_events_square, filtered_events_square),f'dataframe filtered_events_square not the same'    

    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('test')   
    
    #try to plot
    haz_fig = plot_disaster_counts(filtered_events_square)
    assert isinstance(haz_fig, plt.Figure), f'error, It is not a Figure'
    plt.close(haz_fig)

--------------------------------------------------------------------------------
test/test_climate_functions.py
code
'''
This script performs unit testing for the climsight 
   climate
            functions,
ensuring configuration files are correctly loaded ...
It uses pytest to test 
The tests validate both the 
presence of essential config files and the accuracy of data fetched from 
external geocoding services. 
'''

import pytest
import yaml
import warnings
import sys
import os
import requests
import pandas as pd
import matplotlib.pyplot as plt
import re

# Append the directory containing the module to sys.path
module_dir = os.path.abspath('../src/climsight/')
if module_dir not in sys.path:
    sys.path.append(module_dir)


from climate_functions import (
   load_data,
   extract_climate_data
)

base_dir = os.path.dirname(os.path.abspath(__file__))

# Find the right config file
def find_config_file(filename):
    if os.path.exists(filename):
        return filename
    parent_dir_file = os.path.join(base_dir, '..', filename)
    if os.path.exists(parent_dir_file):
        return parent_dir_file
    return None

env_config_path = os.getenv('CONFIG_PATH')
if env_config_path:
    config_path = find_config_file(env_config_path)
else:
    config_path = find_config_file('config.yml')
test_config_path = 'config_test_climate_functions.yml'

def test_config_files_exist():
    assert os.path.exists(config_path), f"Configuration file does not exist: {config_path}"
    assert os.path.exists(test_config_path), f"Test configuration file does not exist: {test_config_path}"


@pytest.fixture
def config_main():
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

@pytest.fixture
def config_test():
    with open(test_config_path, 'r') as file:
        config_data = yaml.safe_load(file)
    config_name = re.sub(r'^config_', '', os.path.basename(config_path).replace('.yml', ''))
    return config_data['config_test'].get(config_name, config_data['config_test']['default'])

def are_dataframes_equal(df1, df2, tol=1e-6):
    """
    Compares two DataFrames for equality within a specified tolerance level,
    ignoring NaN values in comparison.
    Returns True if they are equal within the tolerance, otherwise False.
    """
    try:
        pd.testing.assert_frame_equal(df1, df2, check_dtype=False, atol=tol, 
                                      check_exact=False, check_names=False)
        return True
    except AssertionError:
        return False
      
@pytest.mark.climate    
@pytest.mark.local_data  
def test_climate_data(config_main, config_test):
    lat, lon   = config_test['test_location']['lat'], config_test['test_location']['lon']
    expected_data_dict = config_test['test_location']['data_dict']
    data_path  = config_main['data_settings']['data_path']
    config_name = os.path.basename(config_path).replace('.yml', '')
    if config_name == 'config_tco319':
        expected_csv_file = 'expected_df_climate_data_tco319.csv'
    elif config_name == 'config_tco1279':
        expected_csv_file = 'expected_df_climate_data_tco1279.csv'
    else:
        expected_csv_file = 'expected_df_climate_data.csv'
    
    expected_df_path = os.path.join(base_dir, expected_csv_file)
    expected_df = pd.read_csv(expected_df_path, index_col=0) 
    
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('..') 
    try:
        hist, future = load_data(config_main)
    except Exception as e:
        warnings.warn(f"Failed to load_data(data_path): {str(e)}", RuntimeWarning)
        # Explicitly fail the test with a message
        pytest.fail(f"Test failed due to an error in load_data: {str(e)}, no file probably ?")        

    try:
        df, data_dict = extract_climate_data(lat, lon, hist, future, config_main)
    except Exception as e:
        warnings.warn(f"Failed to extract_climate_data(lat, lon, hist, future, config_main): {str(e)}", RuntimeWarning)
        # Explicitly fail the test with a message
        pytest.fail(f"Test failed due to an error in extract_climate_data: {str(e)}, no file probably ?")        
            
    assert are_dataframes_equal(df,expected_df,tol=1e-6), f'error in dataframes after extract_climate_data'
    assert expected_data_dict == data_dict,f'error in dictionary after extract_climate_data'


   
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('test')
        
        
        

--------------------------------------------------------------------------------
test/test_economic_functions.py
code
'''
This script performs unit testing for the climsight 
   economic
            functions,
ensuring configuration files are correctly loaded ...
It uses pytest to test 
The tests validate both the 
presence of essential config files and the accuracy of data fetched from 
external geocoding services. 
here wi do all the test in : test_population
'''

import pytest
import yaml
import warnings
import sys
import os
import requests
import pandas as pd
import matplotlib.pyplot as plt

# Append the directory containing the module to sys.path
module_dir = os.path.abspath('../src/climsight/')
if module_dir not in sys.path:
    sys.path.append(module_dir)


from economic_functions import (
    get_population,
    plot_population,
    x_year_mean_population   
)

config_path = '../config.yml'
test_config_path = 'config_test_economic_functions.yml'

def test_config_files_exist():
    assert os.path.exists(config_path), f"Configuration file does not exist: {config_path}"
    assert os.path.exists(test_config_path), f"Test configuration file does not exist: {test_config_path}"


@pytest.fixture
def config_main():
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

#config = config_main


@pytest.fixture
def config_test():
    with open(test_config_path, 'r') as file:
        config_data = yaml.safe_load(file)
    return config_data

#config_env = config_data
def are_dataframes_equal(df1, df2, tol=1e-6):
    """
    Compares two DataFrames for equality within a specified tolerance level,
    ignoring NaN values in comparison.
    Returns True if they are equal within the tolerance, otherwise False.
    """
    try:
        pd.testing.assert_frame_equal(df1, df2, check_dtype=False, atol=tol, 
                                      check_exact=False, check_names=False)
        return True
    except AssertionError:
        return False
    
@pytest.mark.economic    
@pytest.mark.local_data  
def test_population(config_main, config_test):
    lat, lon   = config_test['test_location']['lat'], config_test['test_location']['lon']
    country    = config_test['test_location']['country']
    year_step  = config_test['test_location']['year_step']
    start_year = config_test['test_location']['start_year']
    end_year   = config_test['test_location']['end_year']
    
    pop_path   = config_main['pop_path']
    expected_mean_population = pd.read_csv('expected_x_year_mean_population.csv')
    expected_reduced_pop_data = pd.read_csv('expected_population.csv', index_col=0)    
    
    
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('..')  

    # --- test x_year_mean_population 
    mean_population = x_year_mean_population(pop_path, country, year_step=year_step, start_year=start_year, end_year=end_year)
    reduced_pop_data = get_population(pop_path, country)
    population_plot = plot_population(pop_path, country)
    
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('test')
    assert are_dataframes_equal(mean_population,expected_mean_population,tol=1e-6), f'dataframe x_year_mean_population not the same' 
    assert are_dataframes_equal(reduced_pop_data,expected_reduced_pop_data,tol=1e-6), f'dataframe _population not the same'     
    #try to plot
    assert isinstance(population_plot, plt.Figure), f'error, It is not a Figure'
    plt.close(population_plot)    
        
        
        

--------------------------------------------------------------------------------
test/test_rag.py
code
import os
import sys
import unittest
import tempfile
from unittest.mock import patch, MagicMock

# Append the directory containing the module to sys.path
module_dir = os.path.abspath('../src/climsight/')
if module_dir not in sys.path:
    sys.path.append(module_dir)

# make sure the config file gets found (error if line is missing)
os.environ['CONFIG_PATH'] = os.path.abspath('../config.yml')

# Import module functions
from rag import (
    load_rag
)

from langchain_core.documents import Document


class TestLoadRag(unittest.TestCase):
    @patch('rag.is_valid_rag_db', return_value=True) # simulate case where db is valid
    @patch('rag.Chroma')
    @patch('rag.OpenAIEmbeddings')
    def test_load_rag_when_ready(self, mock_openai_embeddings, mock_chroma, mock_is_valid_rag_db):
        # Mock the embeddings and chroma instances
        mock_embedding_instance = MagicMock()
        mock_openai_embeddings.return_value = mock_embedding_instance
        mock_chroma_instance = MagicMock()
        mock_chroma.return_value = mock_chroma_instance

        # Call the function with the mocks
        rag_ready, rag_db = load_rag(embedding_model='text-embedding-3-large', chroma_path='test_chroma_path', openai_api_key='test_key')

        # Assert that OpenAIEmbeddings and Chroma were called when rag_ready is True
        self.assertTrue(rag_ready)
        self.assertIs(rag_db, mock_chroma_instance) # making sure that rag_db is exactly the mocked chroma instance
        mock_openai_embeddings.assert_called_once_with(openai_api_key='test_key', model='text-embedding-3-large')
        mock_chroma.assert_called_once_with(
            persist_directory='test_chroma_path',
            embedding_function=mock_embedding_instance,
            collection_name="ipcc_collection"
        )

    @patch('rag.is_valid_rag_db', return_value=False) # simulate case where db is not valid
    def test_load_rag_when_not_ready(self, mock_is_valid_rag_db):
        # Call the function without valid RAG setup
        rag_ready, rag_db = load_rag(embedding_model='text-embedding-3-large', chroma_path='test_chroma_path', openai_api_key='test_key')

        # Assertions for an invalid RAG database
        self.assertFalse(rag_ready)
        self.assertIsNone(rag_db)
        

# Run the tests
if __name__ == '__main__':
    unittest.main()

--------------------------------------------------------------------------------
test/test_geofunctions.py
code
'''
This script performs unit testing for the climsight geolocation functions,
ensuring configuration files are correctly loaded and geolocation operations 
return accurate results. It uses pytest to test various components, including 
location retrieval and detailed address parsing. The tests validate both the 
presence of essential config files and the accuracy of data fetched from 
external geocoding services. 
'''

import pytest
import yaml
import warnings
import sys
import os
import requests
import requests_mock

# Append the directory containing the module to sys.path
module_dir = os.path.abspath('../src/climsight/')
if module_dir not in sys.path:
    sys.path.append(module_dir)



from geo_functions import (
    get_location,
    where_is_point,
    get_adress_string,
    get_location_details,
    closest_shore_distance,
    get_elevation_from_api,
    fetch_land_use,
    get_soil_from_api,
    is_point_onland,
    is_point_in_inlandwater
)

config_path = '../config.yml'
test_config_path = 'config_test_geofunctions.yml'

def test_config_files_exist():
    assert os.path.exists(config_path), f"Configuration file does not exist: {config_path}"
    assert os.path.exists(test_config_path), f"Test configuration file does not exist: {test_config_path}"


@pytest.fixture
def config_main():
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
    return config

@pytest.fixture
def config_geo():
    with open(test_config_path, 'r') as file:
        config_data = yaml.safe_load(file)
    return config_data

@pytest.fixture
def latlon(config_geo):
    lat = float(config_geo['test_location']['lat'])
    lon = float(config_geo['test_location']['lon'])
    return lat, lon  # This returns a tuple, but we'll unpack this in the function call

@pytest.mark.request
def test_get_location(config_geo):
    
    lat = float(config_geo['test_location']['lat'])
    lon = float(config_geo['test_location']['lon'])    
    expected_address = config_geo['test_location']['expected_address']
    expected_address_string = config_geo['test_location']['expected_address_string']
    expected_location_details = config_geo['test_location']['expected_location_details']
        
    location = get_location(lat, lon)

    message = "\033[91m" + " \n Warning: test can fail because it changes the road unpredictably. \n" + "\033[0m"    

    assert location is not None  , f"get_location: response.status_code not == 200"
    assert 'error' not in location, f"get_location: {location}"
    try:
      assert location['features'][0]['properties']['address'] == expected_address, f"wrong adress"
    except AssertionError as e: 
      warnings.warn(str(e)+message, UserWarning)
      
    address_string = get_adress_string(location)
    try:
        assert address_string == expected_address_string
    except AssertionError as e: 
      warnings.warn(str(e)+message, UserWarning)
        
    location_details = get_location_details(location)
    try:
        assert location_details == expected_location_details
    except AssertionError as e: 
      warnings.warn(str(e)+message, UserWarning)
        

@pytest.mark.mock_request
def test_mock_get_location(config_geo, requests_mock):

    lat = float(config_geo['test_location']['lat'])
    lon = float(config_geo['test_location']['lon'])    
    expected_address = config_geo['test_location']['expected_address']
    expected_address_string = tuple(config_geo['test_location']['expected_address_string'])
    expected_location_details = config_geo['test_location']['expected_location_details']
    expected_location = config_geo['test_location']['expected_location']
    
    mock_url = "https://nominatim.openstreetmap.org/reverse"
    mock_response = expected_location  # Include all the fields expected in the 'properties'

    # Setup mock request with parameters and headers
    requests_mock.get(mock_url, json=mock_response)

    location = get_location(lat,lon)

    message = "\033[91m" + " \n Warning: test can fail because it changes the road unpredictably. \n" + "\033[0m"    

    assert location is not None  , f"get_location: response.status_code not == 200"
    assert 'error' not in location, f"get_location: {location}"
    assert location['features'][0]['properties']['address'] == expected_address, f"wrong adress"
      
    address_string = get_adress_string(location)
    assert address_string == expected_address_string, f"adress string is failed"

    location_details = get_location_details(location)
    assert location_details == expected_location_details
# ---------------------------- test is on land, is lake
        
@pytest.mark.local_data    
def test_is_point_onland(config_geo, config_main):
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('..')  
    natural_e_path = config_main['natural_e_path']
    
    lat, lon = config_geo['test_wetdry']['lat_dry'], config_geo['test_wetdry']['lon_dry']    
    is_on_land, water_body_status = is_point_onland(lat, lon, natural_e_path)
    assert is_on_land == True, f"error in is_point_onland, point({lat},{lon} not on land)"
    
    lat, lon = config_geo['test_wetdry']['lat_oce'], config_geo['test_wetdry']['lon_oce']
    is_on_land, water_body_status = is_point_onland(lat, lon, natural_e_path)
    assert is_on_land == False, f"error in is_point_onland, point({lat},{lon} not in ocean)"

    lat, lon = config_geo['test_wetdry']['lat_lake'], config_geo['test_wetdry']['lon_lake']
    is_on_land, water_body_status = is_point_onland(lat, lon, natural_e_path)
    assert is_on_land == True, f"error in is_point_onland, point({lat},{lon} not on land)"

    lat, lon = config_geo['test_wetdry']['lat_lake2'], config_geo['test_wetdry']['lon_lake2']
    is_on_land, water_body_status = is_point_in_inlandwater(lat, lon)
    assert is_on_land == True, f"error in is_point_in_inlandwater, point({lat},{lon} not in lake)"
    assert water_body_status == 'The selected point is on land and located within the lake.', f"error in is_point_in_inlandwater, point({lat},{lon} not in lake)"

    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('test')
        
#----------------------------- Test wet dry areas 
@pytest.fixture
def out_point_on_land():
    return (True, False, None, False, None, 'The selected point is on land.')

@pytest.fixture
def out_point_in_ocean():
    return (False, False, None, False, None, 'The selected point is in the ocean.')

@pytest.fixture
def out_point_in_lake():
    return (True, True, 'Bodensee', False, None, 'The selected point is on land and in lake Bodensee.')

@pytest.mark.local_data    
def test_where_is_point(config_geo, out_point_on_land, out_point_in_ocean, out_point_in_lake):
    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('..')   

    lat, lon = config_geo['test_wetdry']['lat_dry'], config_geo['test_wetdry']['lon_dry']
    drywet = where_is_point(lat,lon)
    assert drywet == out_point_on_land, f"error in where_is_point, point({lat},{lon} not on land)"

    lat, lon = config_geo['test_wetdry']['lat_oce'], config_geo['test_wetdry']['lon_oce']
    drywet = where_is_point(lat,lon)
    assert drywet == out_point_in_ocean, f"error in where_is_point, point({lat},{lon} not in ocean)"

    lat, lon = config_geo['test_wetdry']['lat_lake'], config_geo['test_wetdry']['lon_lake']
    drywet = where_is_point(lat,lon)
    assert drywet == out_point_in_lake, f"error in where_is_point, point({lat},{lon} not in lake)"

    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('test')
   
@pytest.mark.local_data  
#--------------------------------   closest_shore_distance  
def test_where_is_point(config_geo, config_main):
   #I do not like it (we need to eliminate hardcode paths)
    os.chdir('..')       
    
    lat, lon = config_geo['test_location']['lat'], config_geo['test_location']['lon']
    coastline_shapefile = config_main['coastline_shapefile']
    dist = closest_shore_distance(lat, lon, coastline_shapefile)
    assert dist == pytest.approx(config_geo['test_location']['closest_shore_distance']), f"error in distance to shore"

    #I do not like it (we need to eliminate hardcode paths)
    os.chdir('test')

#--------------------------------   get_elevation_from_api  
#test with request to api
@pytest.mark.request
def test_get_elevation_from_api(config_geo):
    lat, lon = config_geo['test_location']['lat'], config_geo['test_location']['lon']
    elevation = get_elevation_from_api(lat, lon)
    assert elevation == config_geo['test_location']['elevation'], f"error in elevation at point lat={lat}, lon={lon}"    
#test with mock request 
@pytest.mark.mock_request
def test_mock_get_elevation_from_api(config_geo, requests_mock):
    lat, lon = config_geo['test_location']['lat'], config_geo['test_location']['lon']
    exp_elevation = config_geo['test_location']['elevation']
    mock_url = f"https://api.opentopodata.org/v1/etopo1?locations={lat},{lon}"
    mock_response ={'results': [{'dataset': 'etopo1',
                    'elevation': exp_elevation,
                    'location': {'lat': lat, 'lng': lon}}],
                    'status': 'OK'}    

    requests_mock.get(mock_url, json=mock_response)

    elevation = get_elevation_from_api(lat, lon)
    assert elevation == exp_elevation, f"error in elevation at point lat={lat}, lon={lon}"    
     
#--------------------------------   test_fetch_land_use  
@pytest.mark.request
def test_fetch_land_use(config_geo):
    lat, lon = config_geo['test_location']['lat_land_use'], config_geo['test_location']['lon_land_use']
    try:
        land_use_data = fetch_land_use(lon+1, lat)
    except:
        land_use_data = "Not known"
    try:
        current_land_use = land_use_data["elements"][0]["tags"]["landuse"]
    except:
        current_land_use = "Not known"
    try:
        assert current_land_use == config_geo['test_location']['current_land_use']
    except AssertionError as e: 
        message = "\033[91m" + " \n Warning: test can fail because of HTML request. \n" + "\033[0m"    
        warnings.warn(str(e)+message, UserWarning)  

#test with mock request 
@pytest.mark.mock_request
def test_mock_fetch_land_use(config_geo, requests_mock):
    lat, lon = config_geo['test_location']['lat_land_use'], config_geo['test_location']['lon_land_use']
    exp_landuse = config_geo['test_location']['current_land_use']
    
    mock_url = "http://overpass-api.de/api/interpreter"
        
    mock_response ={'version': 0.6,
                    'generator': 'Overpass API 0.7.62.1 084b4234',
                    'osm3s': {'timestamp_osm_base': '2024-05-06T12:58:41Z',
                    'timestamp_areas_base': '2024-05-06T10:46:45Z',
                    'copyright': 'The data included in this document is from www.openstreetmap.org. The data is made available under ODbL.'},
                    'elements': [{'type': 'way', 'id': 565154562, 'tags': {'landuse': exp_landuse}}]}    
    
    requests_mock.get(mock_url, json=mock_response)
    
    land_use_data = fetch_land_use(lon, lat)

    current_land_use = land_use_data["elements"][0]["tags"]["landuse"]
    assert current_land_use == exp_landuse, f"error in land use at point lat={lat}, lon={lon}"  

#--------------------------------   get_soil_from_api  
@pytest.mark.request
def test_get_soil_from_api(config_geo):
    lat, lon = config_geo['test_location']['lat'], config_geo['test_location']['lon']
    try:
        soil = get_soil_from_api(lat, lon)
    except:
        soil = "Not known"
    try:
        assert soil == config_geo['test_location']['soil'], f'error in soil at point  lat={lat}, lon={lon}'
    except AssertionError as e: 
        message = "\033[91m" + " \n Warning: test can fail because of HTML request. \n" + "\033[0m"    
        warnings.warn(str(e)+message, UserWarning)        
    
@pytest.mark.mock_request
def test_mock_get_soil_from_api(config_geo, requests_mock):
    lat, lon = config_geo['test_location']['lat'], config_geo['test_location']['lon']
    
    mock_url = f"https://rest.isric.org/soilgrids/v2.0/classification/query?lon={lon}&lat={lat}&number_classes=5"
        
    mock_response = {'type': 'Point', 'coordinates': [13.37, 52.524],
                     'query_time_s': 0.9068989753723145, 'wrb_class_name': 'Cambisols',
                     'wrb_class_value': 6, 'wrb_class_probability': [['Cambisols', 17],
                     ['Vertisols', 13],  ['Chernozems', 10],  ['Calcisols', 8],  ['Fluvisols', 8]]}
    requests_mock.get(mock_url, json=mock_response)
        
    soil = get_soil_from_api(lat, lon)

    assert soil == config_geo['test_location']['soil'], f'error in soil at point  lat={lat}, lon={lon}'
    


--------------------------------------------------------------------------------
docs/conf.py
code
# Configuration file for the Sphinx documentation builder.
#
# For the full list of built-in configuration values, see the documentation:
# https://www.sphinx-doc.org/en/master/usage/configuration.html

# -- Project information -----------------------------------------------------
# https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information

import os
import sys

sys.path.insert(0, os.path.abspath("../src"))

project = 'Climsight'
copyright = '2024, Climsight contributors'
author = 'Climsight contributors'
release = '0.2.0'

# -- General configuration ---------------------------------------------------
# https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration

extensions = ['sphinx.ext.autodoc', 'sphinx.ext.viewcode']

templates_path = ['_templates']
exclude_patterns = ['_build', 'Thumbs.db', '.DS_Store']



# -- Options for HTML output -------------------------------------------------
# https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output

html_theme = 'sphinx_rtd_theme'
html_static_path = ['_static']

--------------------------------------------------------------------------------
rag/db_generation.py
code
# Database generation based on source (text) files
# only gets executed if run actively and separately

import os
import logging
import yaml
import re

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.documents.base import Document

logger = logging.getLogger(__name__)
logging.basicConfig(
   filename='db_generation.log',
   level=logging.INFO,
   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
   datefmt='%Y-%m-%d %H:%M:%S'
)

# Load config
config_path = os.getenv('CONFIG_PATH', 'config.yml')
with open(config_path, 'r') as file:
    config = yaml.safe_load(file)


def uuid_patternn():
    """Returns a regex pattern for matching any UUID folder name."""
    return re.compile(r"^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$")


def is_valid_rag_db(rag_db_path):
    """Checks if the rag_db folder contains chroma.sqlite3 and non-empty UUID folder."""
    # check for chroma.sqlite3
    chroma_file = os.path.join(rag_db_path, 'chroma.sqlite3')
    if not os.path.exists(chroma_file):
        return False
    # check for non-empty folder with UUID name
    uuid_folder = [f for f in os.listdir(rag_db_path) if os.path.isdir(os.path.join(rag_db_path, f)) and uuid_patternn().match(f)]
    for file in uuid_folder:
        folder_path = os.path.join(rag_db_path, file)
        if os.listdir(folder_path): # check if folder is non-empty
            return True
        
    return False


def are_source_files_available(data_path):
    """Checks if the ipcc_text_reports folder exists and is non-empty."""
    ipcc_reports_path = os.path.join(data_path, 'ipcc_text_reports')
    if not os.path.exists(ipcc_reports_path):
        return False
    # check for non-hidden files
    for file in os.listdir(ipcc_reports_path):
        if not file.startswith('.'):
            return True
        
    # if only hidden files or folder is empty
    return False


def get_file_names(folder_path):
    """
    Gets the names of all text files in a folder. Throws an error if the
    folder contains other files beyond .txt.

    Params:
    folder_path (str): name of the folder where all files are stored.

    Returns:
    file_names (list): list of all file names.
    """
    file_names = []
    for filename in os.listdir(folder_path):
        # ignore hidden files and folders (those that start with '.')
        if filename.startswith('.'):
            logger.info(f"Ignoring hidden file or folder: {filename}")
            continue
        # only allow .txt files
        if filename.endswith('.txt'):
            file_names.append(filename)
        else:
            # Log and raise an error if a non-text file is found
            logger.error(f"Non-text file found: {filename}")
            raise ValueError(f"Non-text file found: {filename}")
    return file_names


def load_docs(file, encoding='utf-8'):
    """
    Loads (and decodes) a text file with langchain textLoader.

    Params:
    file (str): name of the file that is being loaded.
    encoding (str): type of encoding of the text file. Default: utf-8

    Returns:
    documents (list): list of documents loaded
    """
    if not file.endswith('.txt'):
        logger.error(f"Failed to load {file}: Not a text file.")
        return []  # Return an empty list for non-text files

    try:
        loader = TextLoader(file, encoding=encoding, autodetect_encoding=True)  # autodetect encoding is essential!
        documents = loader.load()
        return documents

    except Exception as e:
        logger.error(f"Failed to load {file}: {e}")
        return []


def split_docs(documents, chunk_size=2000, chunk_overlap=200, separators=[" ", ",", "\n"]):
    """
    Splits the passed documents into chunks.

    Params:
    documents (list): list of document objects to be split.
    chunk_size (int): maximum number of characters per chunk. Default: 2000.
    chunk_overlap (int): number of characters to overlap per chunk. Default: 200.
    separators (list): list of characters where text can be split. Default: [" ", ",", "\n"]

    Returns:
    docs (list): list of chunks created from input documents.
    """
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, separators=separators)
    docs = text_splitter.split_documents(documents)
    return docs


def chunk_and_embed_documents(document_path, embedding_model, openai_api_key, chunk_size=2000, chunk_overlap=200, separators=[" ", ",", "\n"]):
    """
    Chunks and embeds documents from the specified directory using provided embedding function.

    Args:
    - document_path (str): The path to the directory containing the documents.
    - embedding_model (OpenAIEmbeddings): The embedding function to use for generating embeddings.
    - chunk_size (int): maximum number of characters per chunk. Default: 2000.
    - chunk_overlap (int): number of characters to overlap per chunk. Default: 200.
    - separators (list): list of characters where text can be split. Default: [" ", ",", "\n"]

    Returns:
    - list: A list of documents with embeddings.
    """
    # load documents
    file_names = get_file_names(document_path)
    all_documents = []
    for file in file_names:
        logger.info(f"Processing file: {file}")
        documents = load_docs(os.path.join(document_path, file))
        all_documents.extend(documents)  # save all of them into one

    if not all_documents:
        logger.info("No documents found for chunking and embedding.")
        return []

    # Chunk documents
    chunked_docs = split_docs(
        documents=all_documents,
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=separators
    )

    logger.info(f"Chunked documents into {len(chunked_docs)} pieces.")

    # embedding documents 
    embedded_docs = []
    embedding_item = OpenAIEmbeddings(openai_api_key=openai_api_key, model=embedding_model) 
    try:
        for doc in chunked_docs:
            embedding = embedding_item.embed_documents([doc.page_content])[0]  # embed_documents returns a list, so we take the first element
            embedded_docs.append({"text": doc.page_content, "embedding": embedding, "metadata": doc.metadata})
    except Exception as e:
        logger.error(f"Failed to embed document chunks: {e}")
        return []

    logger.info(f"Embedded {len(embedded_docs)} document chunks.")
    return embedded_docs


def initialize_rag(config):
    """
    Initializes the RAG database by checking document presence and modification times,
    and performs chunking and embedding if necessary.

    Args:
    - config (dict): configuration dictionary

    Returns:
    - rag_ready (bool): true if RAG database is initialized successfully, false otherwise
    """
    rag_ready = False

    rag_settings = config['rag_settings']
    openai_api_key = os.getenv('OPENAI_API_KEY')
    embedding_model = rag_settings['embedding_model']
    chroma_path = rag_settings['chroma_path']
    document_path = rag_settings['document_path']
    chunk_size = rag_settings['chunk_size']
    chunk_overlap = rag_settings['chunk_overlap']
    separators = rag_settings['separators']

    # check if api key there
    if not openai_api_key:
        logger.warning("No OpenAI API Key found. Skipping RAG initialization.")
        rag_ready = False
        return rag_ready

    # check if documents are present and valid
    if not os.path.exists(document_path) or not any(file.endswith('.txt') for file in os.listdir(document_path)):
        logger.warning("No valid documents found in the specified path. Skipping RAG initialization.")
        rag_ready = False
        return rag_ready

    # Perform chunking and embedding
    try:
        # embedding function, using the langchain chroma package (not chromadb directly)
        langchain_ef = OpenAIEmbeddings(openai_api_key=openai_api_key, model=embedding_model)  # max_retries, request_timeout, retry_min_seconds
        documents = chunk_and_embed_documents(document_path, embedding_model, openai_api_key, chunk_size, chunk_overlap, separators)
        converted_documents = [
            Document(page_content=doc['text'], metadata=doc['metadata'])
            for doc in documents
        ]
        rag_db = Chroma.from_documents(
            documents=converted_documents,
            persist_directory=chroma_path,
            embedding=langchain_ef,
            collection_name="ipcc_collection"
        )
        rag_ready = True
        logger.info(f"RAG ready: {rag_ready}")
        logger.info("RAG database has been initialized and documents embedded.")

        return rag_ready

    except Exception as e:
        logger.error(f"Failed to initialize the RAG database: {e}")
        return rag_ready


def main():
    # paths
    rag_db_path = './rag_db' # using static paths as they are not supposed to be changed and will remain the same.
    data_path = './data'
    rag_ready = False

    if is_valid_rag_db(rag_db_path):
        logger.info("RAG database already exists. No need to initialize.")
        rag_ready = True
        return rag_ready
    
    if not are_source_files_available(data_path):
        logger.warning("""The RAG database does not exists yet and there are no source files available in the data/ipcc_text_reports folder.
                       Please run the download_data.py again and make sure to set the flag --source_files=True.""")
        return rag_ready

    # if rag does not exist yet and the source files are available, run the initialization
    logger.info("Initializing RAG database...")
    rag_ready = initialize_rag(config)
    # danach kann es den Fall geben, dass es trotzdem keine db gibt, weil bei der Initialisierung etwas falsch gelaufen ist (zb. pdf statt txt files in ipcc_text_reports folder)
    # TO-DO write a test for this case!

if __name__ == "__main__":
    main()

--------------------------------------------------------------------------------
src/climsight/test_engine.py
code
from climsight_engine import llm_request, forming_request
import logging
from stream_handler import StreamHandler
import os
import yaml

#import streamlit as st

## ADD to MAin
#Initialize logging at the beginning of your main application
logger = logging.getLogger(__name__)
logging.basicConfig(
   filename='climsight.log',
   level=logging.INFO,
   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
   datefmt='%Y-%m-%d %H:%M:%S'
)

lat = 52.5240
lon = 13.3700
user_message = "Where Am I ?"
skip_llm_call = True
api_key='' 
with open('config.yml', 'r') as file:
      config = yaml.safe_load(file)  
   
# Create a generator object by calling func2
generator = forming_request(config, lat, lon, user_message)

while True:
   try:
      # Get the next intermediate result from the generator
      result = next(generator)
      print(f"Intermediate result: {result}")
   except StopIteration as e:
      # The generator is exhausted, and e.value contains the final result
      content_message, input_params, df_data, figs, data = e.value
      break


stream_handler = StreamHandler()

if not isinstance(skip_llm_call, bool):
    logging.error(f"skip_llm_call must be bool ")
    raise TypeError("skip_llm_call must be  bool")    

if not isinstance(api_key, str):
    logging.error(f"api_key must be a string")
    raise TypeError("api_key must be a string")
if not api_key:
    api_key = os.environ.get("OPENAI_API_KEY") # check if OPENAI_API_KEY is set in the environment
    if not api_key:        
        skip_llm_call=True
        api_key='Dummy' #for longchain api_key should be non empty str


if not skip_llm_call:
   output = llm_request(content_message, input_params, config, api_key, stream_handler)   
   with open('output.txt', 'w') as file:
      # Write the content to the file
      print(output)
      file.write(output) 

--------------------------------------------------------------------------------
src/climsight/climsight.py
code
import logging
import yaml
import os
import sys

from streamlit_interface import run_streamlit
from terminal_interface import run_terminal

#Initialize logging at the beginning of your main application
logger = logging.getLogger(__name__)
logging.basicConfig(
   filename='climsight.log',
   level=logging.INFO,
   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
   datefmt='%Y-%m-%d %H:%M:%S'
)

# Check arguments
skip_llm_call = 'skipLLMCall' in sys.argv
if skip_llm_call:
   logger.info(f"skipLLMCall is in arguments, no call to LLM would be performed")
terminal_call = 'terminal' in sys.argv
if terminal_call:
   logger.info(f"terminal is in arguments, run without Streamlit")   

config = {}
# reading configuration file
if not config:
   config_path = os.getenv('CONFIG_PATH', 'config.yml')
   logger.info(f"reading config from: {config_path}")
   try:
      with open(config_path, 'r') as file:
            config = yaml.safe_load(file)
   except Exception as e:
      logging.error(f"An error occurred while reading the file: {config_path}")
      raise RuntimeError(f"An error occurred while reading the file: {config_path}") from e
# preliminary check config file   
try:
   model_name = config['model_name']
   climatemodel_name = config['climatemodel_name']
   llmModeKey = config['llmModeKey'] 
   data_path = config['data_settings']['data_path']
   coastline_shapefile = config['coastline_shapefile']
   haz_path = config['haz_path']
   pop_path = config['pop_path']
   distance_from_event = config['distance_from_event']
   lat_default = config['lat_default']
   lon_default = config['lon_default']
   year_step = config['year_step']
   start_year = config['start_year']
   end_year = config['end_year']
   system_role = config['system_role']
   rag_settings = config['rag_settings']
   embedding_model = rag_settings['embedding_model']
   chroma_path = rag_settings['chroma_path']
   document_path = rag_settings['document_path']
   chunk_size = rag_settings['chunk_size']
   chunk_overlap = rag_settings['chunk_overlap']
   separators = rag_settings['separators']
   rag_activated = rag_settings['rag_activated']
   rag_template = config['rag_template']
except KeyError as e:
   logging.error(f"Missing configuration key: {e}")
   raise RuntimeError(f"Missing configuration key: {e}")

if not terminal_call:
   run_streamlit(config, skip_llm_call=skip_llm_call, rag_activated=rag_activated, embedding_model=embedding_model, chroma_path=chroma_path)
else:   
   output = run_terminal(config, skip_llm_call=skip_llm_call, embedding_model=embedding_model, chroma_path=chroma_path)

--------------------------------------------------------------------------------
src/climsight/smart_agent.py
code
# smart_agent.py

from pydantic import BaseModel, Field
from typing import Optional, Literal
import netCDF4 as nc
import numpy as np
import os

from langchain.agents import AgentExecutor, create_openai_tools_agent, Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_core.tools import StructuredTool
from langchain_community.document_loaders import WikipediaLoader
from langchain_community.utilities import WikipediaAPIWrapper
from langchain.schema import AIMessage
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate
import requests
from bs4 import BeautifulSoup
from urllib.parse import quote_plus
from langchain.schema import Document

# Import AgentState from climsight_classes
from climsight_classes import AgentState

def smart_agent(state: AgentState, config, api_key):

    lat = float(state.input_params['lat'])
    lon = float(state.input_params['lon'])

    # System prompt
    prompt = f"""
    You are the smart agent of ClimSight. Your task is to retrieve necessary components of the climatic datasets based on the user's request.
    You have access to tools called "get_data_components", "wikipedia_search", and "RAG_search" which you can use to retrieve the necessary environmental data components.
    - "get_data_components" will retrieve the necessary data from the climatic datasets at the location of interest (latitude: {lat}, longitude: {lon}).
    - "wikipedia_search" will help you determine the necessary data to retrieve with the get_data_components tool.
    - "RAG_search" can provide detailed information about environmental conditions for growing corn from your internal knowledge base.
    <Important> ALWAYS call FIRST SIMULTANIOUSLY the wikipedia_search and RAG_search; it will help you determine the necessary data to retrieve with the get_data_components tool. At second step, call the get_data_components tool with the necessary data.</Important>
    Use these tools to get the data you need to answer the user's question.
    After retrieving the data, provide a concise summary of the parameters you retrieved, explaining briefly why they are important. Keep your response short and to the point.
    Do not include any additional explanations or reasoning beyond the concise summary.
    Do not include any chain-of-thought reasoning or action steps in your final answer.

    <Important> 
    For the final response try to follow the following format:
    'The [retrieved values of the parameter] for the [object of interest] at [location] is [value], [according to the Wikipedia article] the required [parameter] [value] for [object of interest] is [value]. [One sentence of clarification]'
    'Repeat for each parameter.'
    </Important>
    """

    #[1] Tool description for netCDF extraction
    class get_data_components_args(BaseModel):
        environmental_data: Optional[Literal["Temperature", "Precipitation", "u_wind", "v_wind"]] = Field(
            default=None,
            description="The type of environmental data to retrieve. Choose from Temperature, Precipitation, u_wind, or v_wind.",
            enum_description={
                "Temperature": "The mean monthly temperature data.",
                "Precipitation": "The mean monthly precipitation data.",
                "u_wind": "The mean monthly u wind component data.",
                "v_wind": "The mean monthly v wind component data."
            }
        )

    def get_data_components(**kwargs):
        # Parse the arguments using the args_schema
        args = get_data_components_args(**kwargs)
        environmental_data = args.environmental_data
        if environmental_data is None:
            return {"error": "No environmental data type specified."}

        lat = float(state.input_params['lat'])
        lon = float(state.input_params['lon'])
        data_path = config['data_settings']['data_path']

        data_files = {
            "Temperature": ("AWI_CM_mm_historical.nc", "tas"),
            "Precipitation": ("AWI_CM_mm_historical_pr.nc", "pr"),
            "u_wind": ("AWI_CM_mm_historical_uas.nc", "uas"),
            "v_wind": ("AWI_CM_mm_historical_vas.nc", "vas")
        }

        if environmental_data not in data_files:
            return {"error": f"Invalid environmental data type: {environmental_data}"}

        file_name, var_name = data_files[environmental_data]
        file_path = os.path.join(data_path, file_name)

        if not os.path.exists(file_path):
            return {"error": f"Data file {file_name} not found in {data_path}"}

        dataset = nc.Dataset(file_path)
        lats = dataset.variables['lat'][:]
        lons = dataset.variables['lon'][:]
        # Find the nearest indices
        lat_idx = (np.abs(lats - lat)).argmin()
        lon_idx = (np.abs(lons - lon)).argmin()
        data = dataset.variables[var_name][:, :, :, lat_idx, lon_idx]
        # Take mean over all axes to get a single value
        point_data = np.mean(data)
        dataset.close()

        return {environmental_data: point_data}

    # Define the data_extraction_tool
    data_extraction_tool = StructuredTool.from_function(
        func=get_data_components,
        name="get_data_components",
        description="Retrieve the necessary environmental data component.",
        args_schema=get_data_components_args
    )

    #[2] Wikipedia processing tool
    def process_wikipedia_article(query: str) -> str:
        from langchain.document_loaders import WikipediaLoader
        from langchain_core.prompts import ChatPromptTemplate
        from langchain_openai import ChatOpenAI

        # Initialize the LLM
        llm = ChatOpenAI(
            openai_api_key=api_key,
            model_name=config['model_name'],
            temperature=0.0
        )

        # Define your custom prompt template
        template = """
        Read the provided  {wikipage} carefully. Extract and present information related to the following keywords relative to {question}:

             Temperature
             Precipitation
             Wind
             Elevation Above Sea Level
             Population
             Natural Hazards
             Soil Type

        Guidelines:

             For each keyword, if information is available in the article, extract and present both qualitative and quantitative information separately.
             Separate the information into two sections: Qualitative and Quantitative for each keyword.
             In the Quantitative section, focus on specific numerical data, measurements, thresholds, or quantitative values associated with the keyword. Include units (e.g., C, mm, km/h) where applicable.
             In the Qualitative section, provide relevant descriptive information that does not include specific numbers.
             If no information is available for a keyword, omit it entirelydo not mention the keyword.
             Present the information in a clear and organized manner.
             Do not include any additional information beyond what is relevant to the listed keywords.

        Example Format:

             Temperature:
                 Quantitative: Requires warm days above 10C (50F) for flowering.
                 Qualitative: Maize is cold-intolerant and must be planted in the spring in temperate zones.
             Wind:
                 Quantitative: Can be uprooted by winds exceeding 60km/h due to shallow roots.
                 Qualitative: Maize pollen is dispersed by wind.
             Soil Type:
                 Quantitative: Prefers soils with a pH between 6.07.5.
                 Qualitative: Maize is intolerant of nutrient-deficient soils and depends on adequate soil moisture.

        Note: Replace the placeholders with the actual qualitative and quantitative information extracted from the article, ensuring that each piece of information is placed in the appropriate section.
        """
        
        class EncyclopediaLoader:
            def __init__(self, topic):
                self.topic = topic

            def load(self):
                # Encode the topic to be URL-friendly
                encoded_topic = quote_plus(self.topic)
                url = f'https://encyclopedia2.thefreedictionary.com/{encoded_topic}'
                
                # Fetch the page
                response = requests.get(url)
                if response.status_code != 200:
                    raise Exception(f"Failed to retrieve article for topic: {self.topic}")
                
                # Parse the HTML content
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # Find the div containing the article
                article_div = soup.find('div', {'id': 'Definition'})
                if not article_div:
                    raise Exception(f"Article content not found for topic: {self.topic}")
                
                # Extract text from all paragraphs within the article div
                paragraphs = article_div.find_all('p')
                article_text = '\n'.join([p.get_text(strip=True) for p in paragraphs])
                document = Document(page_content=article_text, metadata={"source": url})

                
                return document 

        #data_rag = config['rag_settings']['data_path']

        # Create the prompt
        prompt = ChatPromptTemplate.from_template(template)

        # Load the Wikipedia article
        loader = WikipediaLoader(
            query=query,
            load_all_available_meta=True,
            doc_content_chars_max=100000,
            load_max_docs=1
        )
        raw_documents = loader.load()

        try:
            loader = EncyclopediaLoader(query)
            article_text = loader.load().page_content
        except Exception as e:
            print(f"Encyclopedia loader failed: {str(e)}")
            article_text = ""  # Set empty string if encyclopedia lookup fails

        #raw_documents.append(article_text) 
        content_str = 'Encyclopedia article: ' + article_text + '\n' + 'Wikipedia article: ' + raw_documents[0].page_content

        if not raw_documents:
            return "No Wikipedia article found for the query."

        # Run the chain
        chain = prompt | llm
        result = chain.invoke({"wikipage": content_str, "question": query})

        return result

    # Define the args schema for the Wikipedia tool
    class WikipediaSearchArgs(BaseModel):
        query: str = Field(
            description="The topic to search on Wikipedia."
        )

    # Create the Wikipedia tool
    wikipedia_tool = StructuredTool.from_function(
        func=process_wikipedia_article,
        name="wikipedia_search",
        description=(
            "A tool to search Wikipedia for information and process it according to specific guidelines. "
            "Input should be the topic of interest. For example, if the question is about growing corn in southern Germany, "
            "you should input 'corn' as the query."
        ),
        args_schema=WikipediaSearchArgs
    )

    #[3] RAG extraction tool
    class RAGSearchArgs(BaseModel):
        query: str = Field(
            description="The topic to search in the internal knowledge database."
        )
        #domain: str = Field(
        #    description="The domain of the internal knowledge database to search in. For example 'agriculture', 'energy', 'water', 'health', etc."
        #)


    def process_RAG_search(query: str) -> str:
        # Retrieve the path to the vector store
        data_rag = config['rag_articles']['data_path']
        
        # Load the persisted vector store
        embeddings = OpenAIEmbeddings(api_key=api_key)
        vectorstore = Chroma(
            persist_directory=data_rag,
            embedding_function=embeddings
        )
        retriever = vectorstore.as_retriever()

        # Retrieve relevant documents
        retrieved_docs = retriever.get_relevant_documents(query)
        if not retrieved_docs:
            return "No relevant documents found for the query."
        
        # Combine the documents into a single string
        rag_content = '\n\n'.join([doc.page_content for doc in retrieved_docs])
        
            # Define your custom prompt template
        template = """
        Read the provided {rag_content} carefully. Extract and present information related to the following keywords relative to {question}:

             Temperature
             Precipitation
             Wind
             Elevation Above Sea Level
             Population
             Natural Hazards
             Soil Type

        Guidelines:

             For each keyword, if information is available in the article, extract and present both qualitative and quantitative information separately.
             Separate the information into two sections: Qualitative and Quantitative for each keyword.
             In the Quantitative section, focus on specific numerical data, measurements, thresholds, or quantitative values associated with the keyword. Include units (e.g., C, mm, km/h) where applicable.
             In the Qualitative section, provide relevant descriptive information that does not include specific numbers.
             If no information is available for a keyword, omit it entirelydo not mention the keyword.
             Present the information in a clear and organized manner.
             Do not include any additional information beyond what is relevant to the listed keywords.

        Example Format:

             Temperature:
                 Quantitative: Requires warm days above 10C (50F) for flowering.
                 Qualitative: Maize is cold-intolerant and must be planted in the spring in temperate zones.
             Wind:
                 Quantitative: Can be uprooted by winds exceeding 60km/h due to shallow roots.
                 Qualitative: Maize pollen is dispersed by wind.
             Soil Type:
                 Quantitative: Prefers soils with a pH between 6.07.5.
                 Qualitative: Maize is intolerant of nutrient-deficient soils and depends on adequate soil moisture.

        Note: Replace the placeholders with the actual qualitative and quantitative information extracted from the article, ensuring that each piece of information is placed in the appropriate section.
        <Important> DO NOT include schema if no relevant information is found. Just return 'No relevant information found for the query.' AND NOTHING ELSE. </Important>
        """
        
        prompt = ChatPromptTemplate.from_template(template)

        # Initialize the LLM
        llm = ChatOpenAI(
            openai_api_key=api_key,
            model_name=config['model_name'],
            temperature=0.0
        )
        
        # Create the chain with the prompt and LLM
        chain = prompt | llm
        
        # Run the chain with the provided content and question
        result = chain.invoke({"rag_content": rag_content, "question": query})
        
        return result


    # Create the RAG tool
    rag_tool = StructuredTool.from_function(
        func=process_RAG_search,
        name="RAG_search",
        description="A tool to answer questions about environmental conditions for growing corn. For search queries, provide expanded question. For example, if the question is about growing corn, the query should be 'limiting factors for corn growth'.",
        args_schema=RAGSearchArgs
    )

    # Initialize the LLM
    llm = ChatOpenAI(
        openai_api_key=api_key,
        model_name=config['model_name'],
        temperature=0.0
    )

    # List of tools
    tools = [data_extraction_tool, wikipedia_tool, rag_tool]

    # Create the agent with the tools and prompt
    agent = create_openai_tools_agent(
        llm=llm,
        tools=tools,
        prompt=ChatPromptTemplate.from_messages(
            [
                ("system", prompt),
                ("user", state.user),
                MessagesPlaceholder(variable_name="chat_history"),
                MessagesPlaceholder(variable_name="agent_scratchpad"),
            ]
        )
    )

    agent_executor = AgentExecutor(
        agent=agent,
        tools=tools,
        verbose=True,
        return_intermediate_steps=True  # Set to True to capture tool outputs
    )

    # Prepare input for the agent
    agent_input = {
        "input": state.user,
        "chat_history": state.messages,
        "lat": lat,
        "lon": lon
    }

    # Run the agent
    result = agent_executor(agent_input)

    # Extract the tool outputs
    tool_outputs = {}
    for action, observation in result['intermediate_steps']:
        if action.tool == 'wikipedia_search':
            if isinstance(observation, AIMessage):
                tool_outputs['wikipedia_search'] = observation.content
            else:
                tool_outputs['wikipedia_search'] = observation
        elif action.tool == 'get_data_components':
            if isinstance(observation, AIMessage):
                tool_outputs['get_data_components'] = observation.content
            else:
                tool_outputs['get_data_components'] = observation

    # Store the response from the wikipedia_search tool into state
    if 'wikipedia_search' in tool_outputs:
        state.wikipedia_tool_response = tool_outputs['wikipedia_search']

    # Also store the agent's final answer
    smart_agent_response = result['output']
    state.smart_agent_response = {'output': smart_agent_response}

    # Return both smart_agent_response and wikipedia_tool_response
    return {
        'smart_agent_response': state.smart_agent_response,
        'wikipedia_tool_response': state.wikipedia_tool_response
    }
--------------------------------------------------------------------------------
src/climsight/geo_functions.py
code
""" 
Collection of functions for geographic data processing. 
These functions handle tasks such as location lookup, 
distance calculations, and geographic attributes 
extraction.
"""
import streamlit as st
import requests
from shapely.geometry import Point, Polygon, LineString
import geopandas as gpd
import pandas as pd
from pyproj import Geod
from requests.exceptions import Timeout
from functools import lru_cache
import os
import logging
import osmnx as ox


logger = logging.getLogger(__name__)

@lru_cache(maxsize=100)
def get_location(lat, lon):
    """
    Returns the address of a given latitude and longitude using the Nominatim geocoding service.

    Parameters:
    lat (float): The latitude of the location.
    lon (float): The longitude of the location.

    Returns:
    dict: A dictionary containing information about the location.
    """
    # URL for Nominatim API reverse geocoding endpoint
    url = "https://nominatim.openstreetmap.org/reverse"

    params = {
        "lat": lat,
        "lon": lon,
        "format": "geojson",
        "extratags": 1,
        "namedetails": 1,
        "zoom": 18
    }
    headers = {
        "User-Agent": "climsight",
        "accept-language": "en"
    }
    response = requests.get(url, params=params, headers=headers, timeout=5)
    location = response.json()

    # Wait before making the next request (according to terms of use)
    # time.sleep(1)  # Sleep for 1 second

    if response.status_code == 200:
        location = response.json()        
        return location
    else:
        print("Error:", response.status_code, response.reason)
        return None

@lru_cache(maxsize=100)
def is_point_onland(lat, lon, land_path_in):
    """
    Checks if a given point (latitude and longitude) is on land.

    Args:
    lat (float): Latitude of the point.
    lon (float): Longitude of the point.
    config (list): Config

    Returns:
    bool : True is on land, False is in the Ocean.
    str: water_status
    """
    point = Point(lon, lat)

    land_path = os.path.join(land_path_in, 'land/ne_10m_land.shp')
    land_shp = gpd.read_file(land_path)
    is_on_land = land_shp.contains(point).any()
    logging.info(f"Is the point on land? {'Yes.' if is_on_land else 'No.'}")
    
    water_body_status = ""  # Initialize an empty string to store the status
    if not is_on_land: # If point is not on land, no need to check for lakes or rivers
        water_body_status = "The selected point is in the ocean."
    
    return is_on_land, water_body_status

@lru_cache(maxsize=100)
def is_point_in_inlandwater(lat, lon, water_body_status="The selected point is on land."):
    """
    Checks if a given point (latitude and longitude) is in river or lake.

    Args:
    lat (float): Latitude of the point.
    lon (float): Longitude of the point.
    water_body_status (str): string if ocean/lake/...
        
    Returns:
    Tuple: Indicates if the point is on land, in a lake, near a river, and the name of the lake or river if applicable.
    """
    point = Point(lon, lat)

    #request to openstreetmap OSM with osmnx
    no_error = True
    try: 
        distance = 1000
        tags = {'natural':'water'}
        gdf = ox.features.features_from_point((lat,lon),tags,dist=distance)
    except Exception as e:
        logging.error(f"Unexpected error in request with osmnx ot OSM: {e}")
        #raise RuntimeError(f"Unexpected error in get_location: {e}")
        #if error, we assume point is on land
        is_inland_water = False
        no_error = False

    # Check if the point is within any of the geometries in the GeoDataFrame
    if no_error:
        contains_point = gdf['geometry'].apply(lambda geom: geom.contains(point))
        is_inland_water = contains_point.any()
        inland_water_name, inland_water_type = None, None
        if is_inland_water:
            gdf_contains_point = gdf[contains_point]
            try:
                inland_water_name = gdf_contains_point['name'].dropna().iloc[0]
            except:  
                inland_water_name = None
            try:
                inland_water_type = gdf_contains_point['water'].dropna().iloc[0]
            except:
                inland_water_type = None
            
            if inland_water_type:
                water_body_status = water_body_status.rstrip('.') + f" and located within the {inland_water_type if inland_water_type else ' water body'}."
            if inland_water_name:
                inland_water_name = water_body_status.rstrip('.') + f" named {'river ' + inland_water_name if inland_water_name else 'a river'}."

    return is_inland_water, water_body_status

@lru_cache(maxsize=100)
def where_is_point(lat, lon):
    """
    Checks if a given point (latitude and longitude) is on land or water, and identifies the water body's name if applicable.


    Args:
    lat (float): Latitude of the point.
    lon (float): Longitude of the point.
    land_shapefile_path (str): Path to the land shapefile.

    Returns:
    Tuple: Indicates if the point is on land, in a lake, near a river, and the name of the lake or river if applicable.
    """
    
    point = Point(lon, lat)
    
    land_shp = gpd.read_file('./data/natural_earth/land/ne_10m_land.shp')
    is_on_land = land_shp.contains(point).any()
    print(f"Is the point on land? {'Yes.' if is_on_land else 'No.'}")
    if not is_on_land: # If point is not on land, no need to check for lakes or rivers
        water_body_status = "The selected point is in the ocean."
        return is_on_land, False, None, False, None, water_body_status

    water_shp_files = [
    './data/natural_earth/rivers/ne_10m_rivers_lake_centerlines.shp',
    './data/natural_earth/lakes/ne_10m_lakes.shp',
    './data/natural_earth/lakes/ne_10m_lakes_australia.shp',
    './data/natural_earth/lakes/ne_10m_lakes_europe.shp',
    './data/natural_earth/lakes/ne_10m_lakes_north_america.shp',
    './data/natural_earth/rivers/ne_10m_rivers_lake_centerlines.shp',
    './data/natural_earth/rivers/ne_10m_rivers_australia.shp',
    './data/natural_earth/rivers/ne_10m_rivers_europe.shp',
    './data/natural_earth/rivers/ne_10m_rivers_north_america.shp',
    ]
    water_shp = gpd.GeoDataFrame(pd.concat([gpd.read_file(shp) for shp in water_shp_files], ignore_index=True))

    
    # Initialize flags to check if the point is in water
    in_lake = False
    near_river = False
    lake_name = None 
    river_name = None

    for index, feature in water_shp.iterrows():
        geometry = feature.geometry

        if isinstance(geometry, Polygon) and geometry.contains(point):
            in_lake = True
            if 'name' in feature and pd.notnull(feature['name']):
                lake_name = feature.get('name')
            else:
                lake_name = None 
            break  # Stop the loop if the point is in a lake

        # create a buffer (in degree) around the river (line) and check if the point is within it
        elif isinstance(geometry, LineString) and geometry.buffer(0.005).contains(point):
            near_river = True
            if 'name' in feature and pd.notnull(feature['name']):
                river_name = feature.get('name')
            else:
                river_name = None 

    print(f"Is the point in a lake? {'Yes.' if in_lake else 'No.'} {'Name: ' + lake_name if lake_name else ''}")
    print(f"Is the point near a river? {'Yes.' if near_river else 'No.'} {'Name: ' + river_name if river_name else ''}")

    water_body_status = ""  # Initialize an empty string to store the status

    if is_on_land:
        water_body_status = "The selected point is on land"
        if in_lake:
            water_body_status = water_body_status + f" and in {'lake ' + lake_name if lake_name else 'a lake'}."
        elif near_river:
            water_body_status = water_body_status + f" and is near {'river ' + river_name if river_name else 'a river'}."
        else:
            water_body_status = water_body_status + "."

    return is_on_land, in_lake, lake_name, near_river, river_name, water_body_status


#@lru_cache(maxsize=100)
def get_adress_string(location):
    """
    Returns a tuple containing three strings:
    1. A string representation of the location address with all the key-value pairs in the location dictionary.
    2. A string representation of the location address with only the country, state, city and road keys in the location dictionary.
    3. Returning the country within in which the location has been clicked by user as a string.

    Parameters:
    location (dict): A dictionary containing the location address information.

    Returns:
    tuple: A tuple containing three strings.
    """
    address = location['features'][0]['properties']['address']

    location_str = "Address: "
    for key, value in address.items():
        location_str += f"{key}: {value}, "

    location_str = location_str.rstrip(', ') # remove the trailing comma and space

    location_str_for_print = "**Address:** "
    if "country" in address:
        location_str_for_print += f"{address['country']}, "
    if "state" in address:
        location_str_for_print += f"{address['state']}, "
    if "city" in address:
        location_str_for_print += f"{address['city']}, "
    if "road" in address:
        location_str_for_print += f"{address['road']} "
    if "house_number" in address:
        location_str_for_print += f"{address['house_number']}"

    location_str_for_print = location_str_for_print.rstrip(', ')
    country = address.get("country", "")

    return location_str, location_str_for_print, country


#@lru_cache(maxsize=100)
def get_location_details(location):
    """"
    Returns a dictionary containing:
    1. osm_type (e.g. way, node, relation)
    2. category (e.g. amenity, leisure, man_made, railway)
    3. type (e.g. outdoor_seating, hunting_stand, groyne, platform, nature_reserve)
    4. extratags (any additional information that is available, e.g. wikipeida links or opening hours)
    # 5. namedetails (full list of names, may include language variants, older names, references and brands) - currently excluded

    Parameters:
    location (dict): A dictionary containing the location address information.

    Returns:
    extracted_properties: A dictionary containing five elements.
    """
    properties = location['features'][0]['properties']
    extracted_properties = {key: properties[key] for key in ['osm_type', 'category', 'type', 'extratags']} #, 'namedetails']}

    return extracted_properties

@lru_cache(maxsize=100)
def closest_shore_distance(lat: float, lon: float, coastline_shapefile: str) -> float:
    """
    Calculates the closest distance between a given point (lat, lon) and the nearest point on the coastline.

    Args:
        lat (float): Latitude of the point
        lon (float): Longitude of the point
        coastline_shapefile (str): Path to the shapefile containing the coastline data

    Returns:
        float: The closest distance between the point and the coastline, in meters.
    """
    geod = Geod(ellps="WGS84")
    min_distance = float("inf")

    coastlines = gpd.read_file(coastline_shapefile)

    for _, row in coastlines.iterrows():
        geom = row["geometry"]
        if geom.geom_type == "MultiLineString":
            for line in geom.geoms:
                for coastal_point in line.coords:
                    _, _, distance = geod.inv(
                        lon, lat, coastal_point[0], coastal_point[1]
                    )
                    min_distance = min(min_distance, distance)
        else:  # Assuming LineString
            for coastal_point in geom.coords:
                _, _, distance = geod.inv(lon, lat, coastal_point[0], coastal_point[1])
                min_distance = min(min_distance, distance)

    return min_distance


@lru_cache(maxsize=100)
def get_elevation_from_api(lat, lon):
    """
    Get the elevation of a location using the Open Topo Data API.

    Parameters:
    lat (float): The latitude of the location.
    lon (float): The longitude of the location.

    Returns:
    float: The elevation of the location in meters.
    """
    url = f"https://api.opentopodata.org/v1/etopo1?locations={lat},{lon}"
    response = requests.get(url, timeout=3)
    data = response.json()
    return data["results"][0]["elevation"]

@lru_cache(maxsize=100)
def fetch_land_use(lon, lat):
    """
    Fetches land use data for a given longitude and latitude using the Overpass API.

    Args:
    - lon (float): The longitude of the location to fetch land use data for.
    - lat (float): The latitude of the location to fetch land use data for.

    Returns:
    - data (dict): A dictionary containing the land use data for the specified location.
    """
    overpass_url = "http://overpass-api.de/api/interpreter"
    overpass_query = f"""
    [out:json];
    is_in({lat},{lon})->.a;
    area.a["landuse"];
    out tags;
    """
    response = requests.get(overpass_url, params={"data": overpass_query}, timeout=3)
    data = response.json()
    return data

@lru_cache(maxsize=100)
def get_soil_from_api(lat, lon):
    """
    Retrieves the soil type at a given latitude and longitude using the ISRIC SoilGrids API.

    Parameters:
    lat (float): The latitude of the location.
    lon (float): The longitude of the location.

    Returns:
    str: The name of the World Reference Base (WRB) soil class at the given location.
    """
    try:
        url = f"https://rest.isric.org/soilgrids/v2.0/classification/query?lon={lon}&lat={lat}&number_classes=5"
        response = requests.get(url, timeout=3)  # Set timeout to 2 seconds
        data = response.json()
        return data["wrb_class_name"]
    except Timeout:
        return "not found"
  

--------------------------------------------------------------------------------
src/climsight/climate_functions.py
code
"""
Functions for climat data extracting, processing, analysis.
climate patterns, historical and future climate projections
"""
import streamlit as st
import xarray as xr
import numpy as np
import pandas as pd
import glob
import os
import warnings

def load_data(config):
    """
    load climate model data from specified directory patterns

    Args:
        config (dict): configuration dictionary containing data path and file name patterns

    Returns:
        xarray.core.dataset.Dataset, xarray.core.dataset.Dataset : data from historical (hindacst) runs and climate projection
    """   
    try:
        data_path = config['data_settings']['data_path']
        climatemodel_name = config['climatemodel_name']
        historical_pattern = config['data_settings']['historical']
        projection_pattern = config['data_settings']['projection']

        if climatemodel_name == 'tco1279' or climatemodel_name == 'tco319':
            all_files = glob.glob(os.path.join(data_path, '*.nc'))
            hist_files = [f for f in all_files if climatemodel_name in f and historical_pattern in f]
            future_files = [f for f in all_files if climatemodel_name in f and projection_pattern in f]
        elif climatemodel_name == 'AWI_CM':
            hist_files = glob.glob(os.path.join(data_path, f"*{historical_pattern}*.nc"))
            future_files = glob.glob(os.path.join(data_path, f"*{projection_pattern}*.nc"))
        else: 
            warnings.warn("Unknown model type. Cannot evaluate given climate data.")

        if hist_files and climatemodel_name != "AWI_CM":
            hist = xr.open_mfdataset(hist_files, concat_dim='time_counter', combine='nested')
        elif hist_files and climatemodel_name == 'AWI_CM':

            hist = xr.open_mfdataset(hist_files, combine='by_coords', compat='override')
        else:
            raise FileNotFoundError(f"No historical files found matching pattern {historical_pattern} in {data_path}")

        if future_files and climatemodel_name != 'AWI_CM':
            future = xr.open_mfdataset(future_files, concat_dim='time_counter', combine='nested')
        elif future_files and climatemodel_name == 'AWI_CM':

            future = xr.open_mfdataset(future_files, combine='by_coords', compat='override')
        else:
            raise FileNotFoundError(f"No projection files found matching pattern {projection_pattern} in {data_path}")

        return hist, future
    
    except Exception as e:
        raise RuntimeError(f"Failed to load data: {str(e)}")
        #st.error(f"Failed to load data: {str(e)}")
        return None, None

# functions used in extract_climate_data
def select_data(dataset, variable, dimensions, lat, lon):
    """
    Selects data for a given variable at specified latitude and longitude.
    """
    return dataset[variable].sel(**{
        dimensions['latitude']: lat,
        dimensions['longitude']: lon},
        method="nearest") 

def verify_shape(hist_units, future_units, variable):
    """
    Sanity check if dimensions of historical and future data set are fine (mainly relevant for using AWI_CM data)
    """
    if hist_units != future_units:
        warning_msg = f"Shape / Dimension mismatch for {variable}: historical units '{hist_units}' vs future units '{future_units}'."
        warnings.warn(warning_msg)
        print(warning_msg)

def convert_temperature(hist_units, hist_data, future_data):
    """"
    Converts temperature from Kelvin into C and checks for any units beyond K and C (not compatible).
    """
    if 'K' in hist_units: # transformation to Celsius if data in Kelvin (using only hist_units form here on as hist_units and future_units are identical if no error was thrown before)
        hist_data -= 273.15
        future_data -= 273.15
        #print(f"Converted temperature from Kelvin to Celsius.")
    elif 'C' not in hist_units:  # Check if not already in Celsius
        warnings.warn(f"Unexpected temperature units: {hist_units}. Please check the unit manually.")
        #print(f"Units found: {hist_units}")
    return hist_data, future_data

def convert_to_mm_per_month(monthly_precip_kg_m2_s1):
    """"
    Converts kg_m2_s1 to mm per month
    """
    days_in_months = np.array([31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31])
    return monthly_precip_kg_m2_s1 * 60 * 60 * 24 * days_in_months # input in seconds 

def convert_precipitation(hist_units, hist_data, future_data):
    """
    Converts precipitation data from any unit to mm or throws error if unknown unit.
    """
    if 'kg m-2 s-1' in hist_units:
        hist_data = convert_to_mm_per_month(hist_data)
        future_data = convert_to_mm_per_month(future_data)
        #print(f"Converted precipitation from kg/m^2/s to mm/month.")
    elif 'm' in hist_units: # this is not perfectly handled yet, but the awi-cm-3 tco... data comes in unit m but is actually m^2/s
        hist_data = convert_to_mm_per_month(hist_data) * 1000
        future_data = convert_to_mm_per_month(future_data) * 1000
        #print(f"Converted precipitation from kg/m^2/s to mm/month.")
        # hist_data /= 100
        # future_data /= 100
        # print(f"Converted precipitation from m/month to mm/month.") 

    elif 'mm' not in hist_units:  # Check if not already in Celsius
        warnings.warn(f"Unexpected precipitation units: {hist_units}. Please check the unit manually.")
        print(f"Units found: {hist_units}")
    return hist_data, future_data

def process_data(data):
    """
    Processes the given data by squeezing out singleton dimensions, ensuring the 
    remaining dimensions include the month dimension (size 12).
    
    Args:
        data (xarray.DataArray or xarray.Dataset): The climate data to be processed.
    
    Returns:
        xarray.DataArray or xarray.Dataset: The processed climate data with singleton
        dimensions removed.
    """
    # Squeeze out all singleton dimensions from the data
    processed_data = data.squeeze()

    # Check if the squeezed data still contains the month dimension (expected to be size 12)
    if 12 not in processed_data.shape:
        raise ValueError("The month dimension (size 12) is missing from the processed data.")

    return processed_data

def extract_climate_data(lat, lon, hist, future, config):
    """
    Extracts climate data for a given latitude and longitude from historical and future datasets.
    This function then handles different climatic variables and specifically calculates wind speed from u and v wind components.
    
    Args:
        - lat (float): Latitude of the location to extract data for.
        - lon (float): Longitude of the location to extract data for.
        - hist (xarray.Dataset): Historical climate dataset.
        - future (xarray.Dataset): Future climate dataset.
        - config (dict): Configuration dictionary containing variable mappings and dimension settings.

    Returns:
        - df (pandas.DataFrame): DataFrame containing present day and future data for temperature, precipitation, and wind speed for each month of the year, with 'Month' as a column.
        - data_dict (dict): Dictionary containing string representations of the extracted climate data for all variables including historical and future datasets.
    """
    variables = config['variable_mappings']
    dimensions = config['dimension_mappings']
    df = pd.DataFrame({'Month': range(1, 13)})
    data_dict = {}

    # Initialize wind variables
    hist_wind_u = hist_wind_v = future_wind_u = future_wind_v = None

    for key, nc_var in variables.items():
        
        hist_data = select_data(hist, nc_var, dimensions, lat, lon)
        future_data = select_data(future, nc_var, dimensions, lat, lon)

        # THIS IS ONLY A BROAD IDEA - NOT TESTED YET! 
        # Ensure data covers all 12 months, potentially using groupby if data spans multiple years
        # if 'time' in hist_data.dims:
        #     hist_data = hist_data.groupby('time.month').mean('time')  # Averaging over 'time' assuming data includes multiple years
        #     future_data = future_data.groupby('time.month').mean('time')

        # Check if data is in unusual format and reshape if necessary 
        hist_data = process_data(hist_data)
        future_data = process_data(future_data)


        # Get units for both projections
        hist_units = hist_data.attrs.get('units', '')
        future_units = future_data.attrs.get('units', '')

        # check their shape for potential mismatch
        verify_shape(hist_units, future_units, key)

        # perform unit-specific transformations 
        if key == 'Temperature': 
            hist_data, future_data = convert_temperature(hist_units, hist_data, future_data)

        if key == 'Precipitation': 
            hist_data, future_data = convert_precipitation(hist_units, hist_data, future_data)

        if key == 'u_wind':
            hist_wind_u = hist_data
            future_wind_u = future_data
        elif key == 'v_wind':
            hist_wind_v = hist_data
            future_wind_v = future_data
        else: 
            df[f"Present Day {key.capitalize()}"] = hist_data.values
            df[f"Future {key.capitalize()}"] = future_data.values
            
        # Calculate wind speed if both components are present and add to DataFrame
        if hist_wind_u is not None and hist_wind_v is not None:
            hist_wind_speed = np.hypot(hist_wind_u, hist_wind_v)
            future_wind_speed = np.hypot(future_wind_u, future_wind_v)
            df['Present Day Wind Speed'] = hist_wind_speed.values
            df['Future Wind Speed'] = future_wind_speed.values

        # Convert arrays to lists and format to strings with specified precision
        hist_data_list = np.round(hist_data.values, 3).tolist()
        future_data_list = np.round(future_data.values, 3).tolist()

        hist_data_str = ', '.join(f'{x:.3f}' for x in hist_data_list)
        future_data_str = ', '.join(f'{x:.3f}' for x in future_data_list)

        data_dict[f"hist_{key}"] = hist_data_str
        data_dict[f"future_{key}"] = future_data_str

    #print(data_dict)
    return df, data_dict

--------------------------------------------------------------------------------
src/climsight/environmental_functions.py
code
"""
Functions for enviromental data extracting, processing, analysis, plotting.
like biodiversity, natural hazards ....
"""
   
import streamlit as st
import requests
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.ticker import MaxNLocator
from functools import lru_cache

@lru_cache(maxsize=100)
def fetch_biodiversity(lon, lat):
    """
    Fetches biodiversity data for a given longitude and latitude using the GBIF API.

    Args:
    - lon (float): The longitude of the location to fetch biodiversity data for.
    - lat (float): The latitude of the location to fetch biodiversity data for.

    Returns:
    - data (dict): A dictionary containing the biodiversity data for the specified location.
    """
    gbif_api_url = "https://api.gbif.org/v1/occurrence/search"
    params = {
        "decimalLatitude": lat,
        "decimalLongitude": lon,
    }
    response = requests.get(gbif_api_url, params=params, timeout=3)
    biodiv = response.json()

    biodiv_list = []
    seen = set()  # This set will help in avoiding duplicates efficiently
        
    if biodiv['results']:
        for record in biodiv['results']:
            if 'genericName' in record and record.get('taxonRank') != 'UNRANKED':
                generic_name = record['genericName']
                if generic_name not in seen:  # Check if the name has already been added
                    seen.add(generic_name)
                    biodiv_list.append(generic_name)
        biodiversity = ', '.join(biodiv_list)
    else:
        biodiversity = "Not known"
        
    return biodiversity
 
@lru_cache(maxsize=100)
def load_nat_haz_data(haz_path):
    """
    Load natural hazard data from a CSV file and filter relevant columns.

    Args:
    - haz_path (str): File path to the CSV file containing natural hazard data.

    Returns:
    - pandas.DataFrame: Dataset with selected columns ('country', 'year', 'geolocation', 'disastertype', 'latitude', 'longitude').
    """

    haz_dat = pd.read_csv(haz_path)

    # reduce data set to only contain relevant columns
    columns_to_keep = ['country', 'year', 'geolocation', 'disastertype', 'latitude', 'longitude']
    haz_dat = haz_dat.loc[:, columns_to_keep]

    return(haz_dat)

@lru_cache(maxsize=100)
def filter_events_within_square(lat, lon, haz_path, distance_from_event):
    """
    Filter events within a square of given distance from the center point.

    Args:
    - lat (float): Latitude of the center point (rounded to 3 decimal places)
    - lon (float): Longitude of the center point (rounded to 3 decimal places)
    - haz_dat (pandas.DataFrame): Original dataset.
    - distance_from_event (float): Distance in kilometers to form a square.

    Returns:
    - pandas.DataFrame: Reduced dataset containing only events within the square.
    """

    haz_dat = load_nat_haz_data(haz_path)

    # Calculate the boundaries of the square
    lat_min, lat_max = lat - (distance_from_event / 111), lat + (distance_from_event / 111)
    lon_min, lon_max = lon - (distance_from_event / (111 * np.cos(np.radians(lat)))), lon + (distance_from_event / (111 * np.cos(np.radians(lat))))

    # Filter events within the square
    filtered_haz_dat = haz_dat[
        (haz_dat['latitude'] >= lat_min) & (haz_dat['latitude'] <= lat_max) &
        (haz_dat['longitude'] >= lon_min) & (haz_dat['longitude'] <= lon_max)
    ]

    prompt_haz_dat = filtered_haz_dat.drop(columns=['country', 'geolocation', 'latitude', 'longitude'])

    return filtered_haz_dat, prompt_haz_dat

#@lru_cache(maxsize=100) cache the output of a function that returns a matplotlib figure is not straightforward and generally not recommended. 
def plot_disaster_counts(filtered_events):
    """
    Plot the number of different disaster types over a time period for the selected location (within 5km radius).

    Args:
    - filtered_events: Only those natural hazard events that were within a 5 km (or whatever other value is set for distance_from_event) radius of the clicked location.
    Returns:
    - figure: bar plot with results
    """
    if not filtered_events.empty:
        # Group by 'year' and 'disastertype' and count occurrences
        disaster_counts = filtered_events.groupby(['year', 'disastertype']).size().unstack(fill_value=0)
        place = filtered_events['geolocation'].unique()

        # create figure and axes
        fig, ax = plt.subplots(figsize=(10,6))
        
        # Plotting the bar chart
        disaster_counts.plot(kind='bar', stacked=False, ax=ax, figsize=(10,6), colormap='viridis')
        ax.yaxis.set_major_locator(MaxNLocator(integer=True))
        plt.title('Count of different disaster types in ' + place[0] + ' over time')
        plt.xlabel('Year')
        plt.ylabel('Count')
        plt.legend(title='Disaster Type')

        return fig
    else:
        return None

--------------------------------------------------------------------------------
src/climsight/evaluation.py
code
from terminal_interface import run_terminal
import logging
import yaml
import os
import sys
import argparse
import re
import numpy as np

from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

#Initialize logging at the beginning of your main application
logger = logging.getLogger(__name__)
logging.basicConfig(
   filename='climsight_evaluation.log',
   level=logging.INFO,
   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
   datefmt='%Y-%m-%d %H:%M:%S'
)


# Create the parser
parser = argparse.ArgumentParser(description="Process the arguments")
# Add the argument with a default value of an empty string
parser.add_argument('--qa_file', type=str, default='', help='Path to the QA file')
parser.add_argument('--config_path', type=str, default='', help='Path to the config file file')
parser.add_argument('--api_key', type=str, default='', help='API key for the OpenAI API')
parser.add_argument('--llm_model', type=str, default='gpt-3.5-turbo-0125', help='model used for the evaluation (default: gpt-3.5-turbo-0125)')
# Parse the arguments
args = parser.parse_args()

qa_file = args.qa_file
config_path = args.config_path
api_key = args.api_key

if not api_key:
    api_key = os.environ.get("OPENAI_API_KEY") # get the API key from the environment variable
    if not api_key:
        raise ValueError("API key is not provided in the arguments or in the environment variable")
                         
# model used for the evaluation
#llm_model = 'gpt-3.5-turbo-0125'
#llm_model = 'gpt-4o'
llm_model = args.llm_model


# if config path is not provided in arguments, use ENV variable, otherwise use the default value
if not config_path:
    config_path = os.getenv('CONFIG_PATH', 'config.yml')
  
logger.info(f"reading config from: {config_path}")
try:
    with open(config_path, 'r') as file:
        config = yaml.safe_load(file)
except Exception as e:
    logging.error(f"An error occurred while reading the file: {config_path}")
    raise RuntimeError(f"An error occurred while reading the file: {config_path}") from e

# if qa path is not provided in arguments, use default value
if not qa_file:
    qa_file = os.path.join("evaluation", "QA.yml")

logger.info(f"reading QA from: {qa_file}")
try:
    with open(qa_file, 'r') as file:
        question_answers = yaml.safe_load(file)
except Exception as e:
    logging.error(f"An error occurred while reading the file: {qa_file}")
    raise RuntimeError(f"An error occurred while reading the file: {qa_file}") from e

evaluation_template = """You are the evaluation expert. You are going to compare two answers. The first answer is the correct answer. The second answer is from the project Climsight. You will also have the question to which the answers were given.

Follow these steps:

	1.	Understand the Question Context:
		Read the provided question carefully.
		Identify the key elements and specifics of what the question is asking regarding the effects of climate change on human activities.
	2.	Analyze the Provided Answers:
		Read the provided answer from Climsight to evaluate.
		Read the provided correct answer to compare with.
		Identify and note the main points, key arguments, and any supporting data or examples in both answers.
	3.	Compare Answers for Completeness:
		Evaluate if the Climsight answer covers all the key points mentioned in the correct answer.
		Check if there are any critical elements from the correct answer that are missing or inadequately covered in the Climsight answer.
	4.	Assess Accuracy and Relevance:
		Determine the accuracy of the information provided by Climsight by comparing it with the correct answer.
	5.	Evaluate Clarity and Coherence:
		Assess the clarity of the Climsight answer. Is it easy to understand and logically presented?
		Compare the coherence of both answers. Does Climsight`s answer follow a logical flow and structure similar to the correct answer?
	6.	Rate the Answer:
		Assign a score for completeness on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.
		Assign a score for accuracy on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.
		Assign a score for relevance on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.
		Assign a score for clarity and coherence on a scale of 1 to 5, where 1 is the lowest and 5 is the highest.
	7.	Provide Feedback and Suggestions:
		Summarize the strengths and weaknesses of the Climsight answer.
		Provide specific suggestions on how the Climsight answer can be improved to better match the correct answer.

Question: {question}
Answer 1 (correct one): {correct_answer}
Answer 2 (evaluate this answer, climsight): {climsight_answer}

You also need to provide a recomendation on how to improve the answer from Climsight, for example what kind of data are missing.

at the end of the evaluation, you will provide a table with scores following template below:
template for the table, replace the <your score> with the actual scores of your evaluation, do not change separators "," use only "," to separate the values in the table:

#### Scores Table:
Criteria, Score (1-5)
Completeness, <your score>
Accuracy, <your score>
Relevance, <your score>
Clarity and Coherence, <your score>
Mean, <your score>
"""
valid_criteria = ["Completeness", "Accuracy", "Relevance", "Clarity and coherence", "Mean"]

def request_answers_from_climsight(question_answers, series = 'ipcc'):
    """_summary_
    return answers from the climsight for the given series of questions

    Args:
        question_answers (dictionary): dictionary with questions, answers, promts, lon, lat ...
        series (str, optional): _description_. Defaults to 'ipcc'.

    Returns:
        output_answers (dictionry): Answers from the climsight
    """
    # Create a dictionary to store the outputs
    output_answers = []

    # Iterate over the questions and run the terminal command
    for qa_indx in range(len(question_answers[series])):
        user_message = question_answers[series][qa_indx].get('promt', '')
        user_message = user_message + ' ' + question_answers[series][qa_indx]['question']
        lon = question_answers[series][qa_indx].get('lon', 13.37)
        lat = question_answers[series][qa_indx].get('lat', 52.524)
        output = run_terminal(config, skip_llm_call=False, lon=lon, lat=lat, user_message=user_message, show_add_info='n', verbose=False)
        output_answers.append(output)

    return output_answers

def evaluate_answers(question_answers, climsight_answers, series, llm_model, evaluation_template):
    """_summary_
       Evaluate the answers from the Climsight by comparing them with the correct answers 
    Args:
        question_answers (dict): questions with the correct answers
        climsight_answers (_type_): answers on the question from question_answers with the Climsight
        series (_type_): 'ipcc' or 'gerics', or ...1
        llm_model (_type_): type of the model used for the evaluation gp-3.5-turbo-0125, gpt-4o, ...
        evaluation_template (_type_): template for the evaluation

    Returns:
        dict : return the evaluation of the answers
    """
    llm = ChatOpenAI(model=llm_model, api_key=api_key)
    custom_rag_prompt = PromptTemplate.from_template(evaluation_template)
 
    rag_chain = (
        {"correct_answer": RunnablePassthrough(), "climsight_answer": RunnablePassthrough(), "question": RunnablePassthrough()}
        | custom_rag_prompt
        | llm
        | StrOutputParser()
    )

    evaluation = []
    
    for qa_indx in range(len(climsight_answers)):
        print("Evaluation for question: ", qa_indx+1)
        # Prepare inputs for the chain
        question =  question_answers[series][qa_indx]['question']
        correct_answer = question_answers[series][qa_indx]['answer']
        climsight_answer = climsight_answers[qa_indx]
        inputs = {
            "question": question,
            "correct_answer": correct_answer,
            "climsight_answer": climsight_answer
        }

        # Invoke the chain
        result = rag_chain.invoke(inputs)
        evaluation.append(result)
    return evaluation

def parse_evaluation(evaluation, valid_criteria):
    """Parse the evaluation and extract the scores for each criterion 
    Args:
        evaluation (dict): evaluation of the answers (from evaluate_answers)
        valid_criteria (list): list of valid criteria ['Completeness', 'Accuracy', 'Relevance', 'Clarity and coherence', 'Mean']

    Returns:
         all_scores (dict), mean_scores (dict): return the scores for each criterion and the mean scores
    """
    # parse the evaluation
        
    # Regular expressions to find the relevant lines
    pattern_comma = re.compile(r'([\w\s]+),\s(\d+\.?\d*)')
    pattern_table = re.compile(r'\|\s*([\w\s]+?)\s*\|\s*(\d+\.?\d*)\s*\|')

    # List of valid criteria
    valid_criteria_lower = [crit.lower() for crit in valid_criteria]

    # Initialize all_scores dictionary with NaNs
    all_scores = {crit: [np.nan] * len(evaluation) for crit in valid_criteria}

    for eval_index, text in enumerate(evaluation):
        # Split text into lines to process each line individually
        lines = text.strip().split('\n')
        for line in lines:
            # Determine if the text is in table format or comma-separated format
            if '|' in text:
                matches = pattern_table.findall(text)
            else:
                matches = pattern_comma.findall(text)
            # Add matches to the dictionary if they are in the valid criteria
            for match in matches:
                criterion = match[0].strip().lower()  # Convert to lowercase for comparison
                score = float(match[1].strip())
                for i, valid_criterion in enumerate(valid_criteria_lower):
                    if valid_criterion in criterion:
                        all_scores[valid_criteria[i]][eval_index] = score

    # Check for any criteria that do not have the expected number of scores
    for crit in valid_criteria:
        if np.isnan(all_scores[crit]).any():
            print(f"Warning: {crit} has {all_scores[crit].count(np.nan)} NaN values")
            
    mean_scores = {crit: np.nanmean(all_scores[crit]) for crit in valid_criteria}            

    return all_scores, mean_scores

#  request Climsight for answers
answers_ipcc = request_answers_from_climsight(question_answers, series = 'ipcc')
answers_gerics = request_answers_from_climsight(question_answers, series = 'gerics')
print("---------   Answers from Climsight ready. ------------------------------")

evaluation_ipcc = evaluate_answers(question_answers, answers_ipcc, 'ipcc', llm_model, evaluation_template)
all_scores_ipcc, mean_scores_ipcc = parse_evaluation(evaluation_ipcc, valid_criteria)

evaluation_gerics = evaluate_answers(question_answers, answers_gerics, 'gerics', llm_model, evaluation_template)
all_scores_gerics, mean_scores_gerics = parse_evaluation(evaluation_gerics, valid_criteria)

### print all scores, with explanaiton
print("-----------------------------------------------------------------------")
print("-----------------------------------------------------------------------")
print("-----------------------------------------------------------------------")
print(" Results of the evaluation for IPCC quesitons: ")
print("Mean scores: ", mean_scores_ipcc)
print("-----------------------------------------------------------------------")
print(" Results of the evaluation for GERICS quesitons: ")
print("Mean scores: ", mean_scores_gerics)

    
    
# Write text content to a text file
filetosave = os.path.join("evaluation", "evaluation_report.txt")
with open(filetosave, "w") as file:
    file.write("Evaluation of the Climsight\n")
    file.write("LLM model used for the Climsight answers: " + config['model_name'] + "\n")
    file.write("LLM model used for the evaluation: " + llm_model + "\n")
    file.write("    Results of the evaluation for IPCC quesitons: \n")
    file.write("        mean scores: \n")
    for k in mean_scores_ipcc.keys():
        file.write('            ' + k + ': ' + str(mean_scores_ipcc[k])+ '\n')
    file.write("    Results of the evaluation for GERICS quesitons: \n")
    file.write("        mean scores: \n")
    for k in mean_scores_gerics.keys():
        file.write('            ' + k + ': ' + str(mean_scores_gerics[k]) + '\n')
    file.write(" -------------------------------------------------------------------------- \n")
    file.write("    Detailed scores for IPCC questions: \n")
    for k in mean_scores_ipcc.keys():
        file.write('            ' + k + ': ' + str(all_scores_ipcc[k])+ '\n')
    file.write("\n")        
    file.write("    Detailed scores for GERICS questions: \n")
    for k in mean_scores_ipcc.keys():
        file.write('            ' + k + ': ' + str(all_scores_gerics[k])+ '\n')            
        
filetosave = os.path.join("evaluation", "evaluation_answers.yml")
evaluation_dict = {'ipcc': evaluation_ipcc, 'all_scores_ipcc':all_scores_ipcc, 'mean_scores_ipcc':mean_scores_ipcc, 
                        'gerics': evaluation_gerics, 'all_scores_gerics':all_scores_gerics,'mean_scores_gerics':mean_scores_gerics}
# Save combined_dict to a YAML file
with open(filetosave, "w") as file:
    yaml.dump(evaluation_dict, file, default_flow_style=False)

--------------------------------------------------------------------------------
src/climsight/economic_functions.py
code
"""
Set of functions dedicated to economic and demographic data.
This module includes tools for population studies, economic impact
assessments, and demographic trends extraction/analysis.
"""
import pandas as pd
import datetime
import matplotlib.pyplot as plt

def get_population(pop_path, country):
    """
    Extracts population data (by UN) for a given country.

    Args:
    - pop_path: Path where the population data is stored
    - country: Takes the country which is returned by the geolocator

    Returns:
    - red_pop_data (pandas.DataFrame): reduced DataFrame containing present day and future values for only the following variables:
        - TPopulation1July (as of 1 July, thousands)
        - PopDensity (as of 1 July, persons per square km)
        - PopGrowthRate (percentage)
        - LEx (Life Expactancy at Birth, both sexes, in years)
        - NetMigrations (Number of Migrants, thousands)    
    """
    pop_dat = pd.read_csv(pop_path)

    unique_locations = pop_dat['Location'].unique()
    my_location = country

    # check if data is available for the country that we are currently investigating
    if my_location in unique_locations:
        country_data = pop_dat[pop_dat['Location'] == country]
        red_pop_data = country_data[['Time', 'TPopulation1July', 'PopDensity', 'PopGrowthRate', 'LEx', 'NetMigrations']]
        return red_pop_data
    else:
        print(f"No population data available {'for' +  country if country else ''}.")
        return None
    
def plot_population(pop_path, country):
    """
    Plots population data (by UN) for a given country.

    Args:
    - pop_path: Path where the population data is stored
    - country: Takes the country which is returned by the geolocator

    Returns:
    - plot: visual representation of the data distribution    
    """
    reduced_pop_data = get_population(pop_path, country)
    
    today = datetime.date.today()
    current_year = today.year

    if reduced_pop_data is not None and not reduced_pop_data.empty:
        fig, ax1 = plt.subplots(figsize=(10,6))
        plt.grid()

        # Total population data
        ax1.plot(reduced_pop_data['Time'], reduced_pop_data['TPopulation1July'], label='Total Population', color='blue')
        ax1.set_xlabel('Time')
        ax1.set_ylabel('People in thousands', color='blue')
        ax1.tick_params(axis='y', labelcolor='blue')

        # life expectancy
        ax2 = ax1.twinx()
        ax2.spines.right.set_position(('axes', 1.1))
        ax2.bar(reduced_pop_data['Time'], reduced_pop_data['LEx'], label='Life Expectancy', color='purple', alpha=0.1)
        ax2.set_ylabel('Life expectancy in years', color='purple', )
        ax2.tick_params(axis='y', labelcolor='purple')

        # population growth data
        ax3 = ax1.twinx()
        ax3.plot(reduced_pop_data['Time'], reduced_pop_data['PopGrowthRate'], label='Population Growth Rate', color='green')
        ax3.set_ylabel('Population growth rate in %', color='green')
        ax3.tick_params(axis='y', labelcolor='green')

        # Net Migrations
        ax4 = ax1.twinx()
        ax4.spines.right.set_position(('axes', 1.2))
        ax4.plot(reduced_pop_data['Time'], reduced_pop_data['NetMigrations'], label='Net Migrations', color='black', linestyle='dotted')
        ax4.set_ylabel('Net migrations in thousands', color='black')
        ax4.tick_params(axis='y', labelcolor='black')
        ax4.axvline(x=current_year, color='orange', linestyle='--', label=current_year)

        lines, labels = ax1.get_legend_handles_labels()
        lines2, labels2 = ax2.get_legend_handles_labels()
        lines3, labels3 = ax3.get_legend_handles_labels()
        lines4, labels4 = ax4.get_legend_handles_labels()
        ax4.legend(lines+lines2+lines3+lines4, labels+labels2+labels3+labels4, loc='center right')

        plt.title(('Population changes in ' + country))
        return fig 
    else:
        return None
    
def calc_mean(years, dataset):
    """
    Calculates the mean of every column of a dataframe over a given time period and returns those means.

    Parameters:
    years (int): The time period that one is interested in to be averaged.
    dataset (pandas data frame): The corresponding data set. It has to have a column called 'Time' in datetime format.

    Returns:
    pandas data frame: A data frame with the means calculated for the given time span.
    """
    years = str(years) + 'A'
    dataset.set_index('Time', inplace=True) # Set the 'Time' column as the index
    numeric_columns = dataset.select_dtypes(include='number')
    dataset = numeric_columns.resample(years).mean() # Resample the numeric data in x-year intervals and calculate the mean
    dataset.reset_index(inplace=True) # Reset the index to have 'Time' as a regular column
    dataset['Time'] = dataset['Time'].dt.year # and normal year format
    
    return dataset
 
def x_year_mean_population(pop_path, country, year_step=1, start_year=None, end_year=None):
    """
    Returns a reduced data set with the means calculated for every column over a given time span

    Parameters:
    pop_path (string): Path where the data is stored.
    country (string): The country which has been clicked on the map by the user.
    year_step (int): How many years shall be aggregated.
    start_year (int): The year from which onward population data is considered.
    end_year (int): The year until which population data is considered.

    Returns:
    pandas data frame: A data frame containing the mean population data values for a given time period.
    """
    # Check if start_year and end_year are within the allowed range
    if (start_year is not None and (start_year < 1950 or start_year > 2100)) or \
       (end_year is not None and (end_year < 1950 or end_year > 2100)):
        print("Warning: Start and end years must be between 1950 and 2100.")
        return None
    
    population_xY_mean = get_population(pop_path, country)
    if population_xY_mean is None:
        print(f"No population data available for {country}.")
        return None
    column_to_remove = ['LEx', 'NetMigrations'] # change here if less / other columns are wanted
    

    if not population_xY_mean.empty:
        population_xY_mean = population_xY_mean.drop(columns=column_to_remove)

        population_xY_mean['Time'] = pd.to_datetime(population_xY_mean['Time'], format='%Y')

        # Filter data based on start_year and end_year
        if start_year is not None:
            start_year = max(min(start_year, 2100), 1950)
            population_xY_mean = population_xY_mean[population_xY_mean['Time'].dt.year >= start_year]
        if end_year is not None:
            end_year = max(min(end_year, 2100), 1950)
            population_xY_mean = population_xY_mean[population_xY_mean['Time'].dt.year <= end_year]

        # Subdivide data into two data frames. One that contains the last complete x-year period (z-times the year_step) and the rest (modulo). For each data set the mean is calculated.
        modulo_years = len(population_xY_mean['Time']) % year_step 
        lastFullPeriodYear = population_xY_mean['Time'].dt.year.iloc[-1] - modulo_years  
        FullPeriod = population_xY_mean[population_xY_mean['Time'].dt.year <= lastFullPeriodYear]
        RestPeriod = population_xY_mean[population_xY_mean['Time'].dt.year > lastFullPeriodYear]

        # calculate mean for each period
        FullPeriodMean = calc_mean(year_step, FullPeriod)
        RestPeriodMean = calc_mean(modulo_years - 1, RestPeriod)
        RestPeriodMean = RestPeriodMean.iloc[1:] # drop first row as it will be same as last one of FullPeriodMean

        combinedMean  = pd.concat([FullPeriodMean, RestPeriodMean], ignore_index=True) # combine back into one data set

        new_column_names = {
            'TPopulation1July': 'TotalPopulationAsOf1July',
            'PopDensity': 'PopulationDensity',
            'PopGrowthRate': 'PopulationGrowthRate',
            # 'LEx': 'LifeExpectancy',
            # 'NetMigrations': 'NettoMigrations'  
        }
        combinedMean.rename(columns=new_column_names, inplace=True)

        return combinedMean
    
    else:
        return None
    
--------------------------------------------------------------------------------
src/climsight/__init__.py
code

--------------------------------------------------------------------------------
src/climsight/streamlit_interface.py
code
"""
    Streamlit App Wrapper Module 
"""
#general 
import logging
import yaml
import os
import pandas as pd

#streamlit packeges
import streamlit as st
from streamlit_folium import st_folium
import folium

# rag
from rag import load_rag 

# climsight modules
from stream_handler import StreamHandler
from data_container import DataContainer
from climsight_engine import llm_request, forming_request, location_request

logger = logging.getLogger(__name__)

data_pocket = DataContainer()

def run_streamlit(config, api_key='', skip_llm_call=False, rag_activated=True, embedding_model='', chroma_path=''):
    """
    Runs the Streamlit interface for ClimSight, allowing users to interact with the system.
    Args:
        - config (dict): Configuration, default is an empty dictionary.   
        - api_key (string): API Key, default is an empty string.
        - skip_llm_call (bool): If True - skip final call to LLM
        - rag_activated (bool): whether or not to include the text based rag
        - embedding_model (str): embedding model to be used for loading the Chroma database.
        - chroma_path (str): Path where the Chroma database is stored.
    Returns:
        None
    """     
  
    # Config
    try:
        climatemodel_name = config['climatemodel_name']
        lat_default = config['lat_default']
        lon_default = config['lon_default']
    except KeyError as e:
        logging.error(f"Missing configuration key: {e}")
        raise RuntimeError(f"Missing configuration key: {e}")   

    if not isinstance(skip_llm_call, bool):
        logging.error(f"skip_llm_call must be bool ")
        raise TypeError("skip_llm_call must be  bool")    
    
    if not isinstance(api_key, str):
        logging.error(f"api_key must be a string ")
        raise TypeError("api_key must be a string")
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY") # check if OPENAI_API_KEY is set in the environment

    #read data while loading here 
    ##### like hist, future = load_data(config)

    clicked_coords = None
  

    st.title(
        " :cyclone: \
            :ocean: :globe_with_meridians:  Climate Foresight"
    )
    # :umbrella_with_rain_drops: :earth_africa:  :tornado:

    # Define map and handle map clicks
    m = folium.Map(location=[lat_default, lon_default], zoom_start=13)
    with st.sidebar:
        #with st.form(key='side_form'):
        #    location_button = st.form_submit_button(label='Get location info')
        #    if location_button:
        #        st.markdown()
        map_data = st_folium(m)
            
    if map_data:
        clicked_coords = map_data["last_clicked"]
        if clicked_coords:
            lat_default = clicked_coords["lat"]
            lon_default = clicked_coords["lng"]

    # Wrap the input fields and the submit button in a form
    with st.form(key='my_form'):
        user_message = st.text_input(
            "Describe the activity that you would like to evaluate for this location:"
        )
        col1, col2 = st.columns(2)
        lat = col1.number_input("Latitude", value=lat_default, format="%.4f")
        lon = col2.number_input("Longitude", value=lon_default, format="%.4f")
        show_add_info = st.toggle("Provide additional information", value=False, help="""If this is activated you will see all the variables
                                that were taken into account for the analysis as well as some plots.""")
        llmModeKey_box = st.radio("Select LLM mode ", key="visibility", options=["Direct", "Agent (experimental)"])
    
        # Include the API key input within the form only if it's not found in the environment
        if not api_key:
            api_key_input = st.text_input(
                "OpenAI API key",
                placeholder="Enter your OpenAI API key here"
            )

        # Replace the st.button with st.form_submit_button
        submit_button = st.form_submit_button(label='Generate')

        
        
    # RUN submit button 
        if submit_button and user_message:
            if not api_key:
                api_key = api_key_input
            if (not api_key) and (not skip_llm_call):
                st.error("Please provide an OpenAI API key.")
                st.stop()
            # Update config with the selected LLM mode
            config['llmModeKey'] = "direct_llm" if llmModeKey_box == "Direct" else "agent_llm"    
            config['show_add_info'] = show_add_info
            
            # Creating a potential bottle neck here with loading the db inside the streamlit form, but it works fine 
            # for the moment. Just making a note here for any potential problems that might arise later one. 
            # Load RAG
            if not skip_llm_call and rag_activated:
                try:
                    logger.info("RAG is activated and skipllmcall is False. Loading RAG database...")
                    rag_ready, rag_db = load_rag(embedding_model, chroma_path, api_key) # load the RAG database 
                except Exception as e:
                    st.error(f"Loading of the RAG database failed unexpectedly, please check the logs. {e}")
                    logger.warning(f"RAG database initialization skipped or failed: {e}")
                    rag_ready = False
                    rag_db = None
                 
            is_on_land = True

            if config['llmModeKey'] == "direct_llm":
                # Call the forming_request function
                with st.spinner("Getting info on a point..."):
                    # Create a generator object by calling func2
                    generator = forming_request(config, lat, lon, user_message)
                    while True:
                        try:
                            # Get the next intermediate result from the generator
                            result = next(generator)
                            st.markdown(f"{result}")
                        except StopIteration as e:
                            # The generator is exhausted, and e.value contains the final result
                            
                            gen_output = e.value
                            # check if Error ocure:
                            if isinstance(gen_output,str):
                                if "Error" in gen_output:
                                    if "point_is_in_ocean" in gen_output:
                                        is_on_land = False
                                        st.markdown(f"The selected point is in the ocean.\n Please choose a location on land.")
                            else:    
                                content_message, input_params, df_data, figs, data = e.value
                                data_pocket.df['df_data'] = df_data
                                data_pocket.figs = figs
                                data_pocket.data = data
                            break            
            else:
                # Agent LLM mode (load only location info)
                with st.spinner("Getting info on a point..."):
                    st.markdown(f"**Coordinates:** {round(lat, 4)}, {round(lon, 4)}")
                    # get first location information only, input_params and content_message are only partly filled
                    content_message, input_params = location_request(config, lat, lon)
                    if not input_params:
                        is_on_land = False
                        st.markdown(f"The selected point is in the ocean.\n Please choose a location on land.")
                    else:
                        # extend input_params with user_message
                        input_params['user_message'] = user_message
                        content_message = "Human request: {user_message} \n " + content_message
                        st.markdown(f"{input_params['location_str_for_print']}")
                        if input_params['is_inland_water']:
                            st.markdown(f"""{input_params['water_body_status']}: Our analyses are currently only meant for land areas. Please select another location for a better result.""")

            if is_on_land:        
                with st.spinner("Generating..."):
                    chat_box = st.empty()
                    stream_handler = StreamHandler(chat_box, display_method="write")
                    if not skip_llm_call:
                        output = llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db, data_pocket)   

                    # PLOTTING ADDITIONAL INFORMATION
                    if show_add_info: 
                        figs = data_pocket.figs
                        data = data_pocket.data
                        if 'df_data' in data_pocket.df:
                            df_data = data_pocket.df['df_data']
                        else:
                            df_data = None
                        st.subheader("Additional information", divider='rainbow')
                        if 'lat' and 'lon' in input_params:
                            st.markdown(f"**Coordinates:** {input_params['lat']}, {input_params['lon']}")
                        if 'elevation' in input_params:
                            st.markdown(f"**Elevation:** {input_params['elevation']} m")
                        if 'current_land_use' in input_params:  
                            st.markdown(f"**Current land use:** {input_params['current_land_use']}")
                        if 'soil' in input_params:
                            st.markdown(f"**Soil type:** {input_params['soil']}")
                        if 'biodiv' in input_params:    
                            st.markdown(f"**Occuring species:** {input_params['biodiv']}")
                        if 'distance_to_coastline' in input_params:  
                            st.markdown(f"**Distance to the shore:** {round(float(input_params['distance_to_coastline']), 2)} m")
                        # Climate Data
                        if df_data is not None and not df_data.empty:
                            st.markdown("**Climate data:**")
                            st.markdown(
                                "Near surface temperature (in C)",
                            )
                            st.line_chart(
                                df_data,
                                x="Month",
                                y=["Present Day Temperature", "Future Temperature"],
                                color=["#1f77b4", "#d62728"],
                            )
                            st.markdown(
                                "Precipitation (in mm)",
                            )
                            st.line_chart(
                                df_data,
                                x="Month",
                                y=["Present Day Precipitation", "Future Precipitation"],
                                color=["#1f77b4", "#d62728"],
                            )
                            st.markdown(
                                "Wind speed (in m*s-1)",
                            )
                            st.line_chart(
                                df_data,
                                x="Month",
                                y=["Present Day Wind Speed", "Future Wind Speed"],
                                color=["#1f77b4", "#d62728"],
                            )
                            # Determine the model information string based on climatemodel_name
                            if climatemodel_name == 'AWI_CM':
                                model_info = 'AWI-CM-1-1-MR, scenarios: historical and SSP5-8.5'
                            elif climatemodel_name == 'tco1279':
                                model_info = 'AWI-CM-3 TCo1279_DART, scenarios: historical (2000-2009) and SSP5-8.5 (2090-2099)'
                            elif climatemodel_name == 'tco319':
                                model_info = 'AWI-CM-3 TCo319_DART, scenarios: historical (2000-2009), and SSP5-8.5 (2090-2099)'
                            else:
                                model_info = 'unknown climate model'

                            with st.expander("Source"):
                                st.markdown(model_info)

                        # Natural Hazards
                        if 'haz_fig' in figs:
                            st.markdown("**Natural hazards:**")
                            st.pyplot(figs['haz_fig']['fig'])
                            with st.expander("Source"):
                                st.markdown(figs['haz_fig']['source'])

                        # Population Data
                        if 'population_plot' in figs:
                            st.markdown("**Population Data:**")
                            st.pyplot(figs['population_plot']['fig'])
                            with st.expander("Source"):
                                st.markdown(figs['population_plot']['source'])
                            
    return

--------------------------------------------------------------------------------
src/climsight/launch.py
code
import subprocess
import os
import sys

def launch_streamlit():
    # Get the directory where launch.py is located
    launch_dir = os.path.dirname(os.path.realpath(__file__))
   
    # Construct the absolute path to climsight.py
    climsight_path = os.path.join(launch_dir, "climsight.py")
    
    # Check if 'skipLLMCall' argument is provided
    skip_llm_call = 'skipLLMCall' in sys.argv

    # Prepare the command to run
    command = ["streamlit", "run", climsight_path]    
    
    if skip_llm_call:
        climsight_path = climsight_path + " skipLLMCall"
    if skip_llm_call:
        command.append("skipLLMCall") 
        
    # Run the command with the absolute path
    subprocess.run(command)

--------------------------------------------------------------------------------
src/climsight/rag.py
code
import os
import logging
import yaml
import re

from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI
from langchain_core.documents.base import Document

logger = logging.getLogger(__name__)
logging.basicConfig(
   filename='climsight.log',
   level=logging.INFO,
   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
   datefmt='%Y-%m-%d %H:%M:%S'
)

# Load config
config_path = os.getenv('CONFIG_PATH', 'config.yml')
with open(config_path, 'r') as file:
    config = yaml.safe_load(file)


def uuid_pattern():
    """Returns a regex pattern for matching any UUID folder name."""
    return re.compile(r"^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$")


def is_valid_rag_db(rag_db_path):
    """Checks if the rag_db folder contains chroma.sqlite3 and non-empty UUID folder."""
    # check for chroma.sqlite3
    chroma_file = os.path.join(rag_db_path, 'chroma.sqlite3')
    if not os.path.exists(chroma_file):
        return False
    # check for non-empty folder with UUID name
    uuid_folder = [f for f in os.listdir(rag_db_path) if os.path.isdir(os.path.join(rag_db_path, f)) and uuid_pattern().match(f)]
    for file in uuid_folder:
        folder_path = os.path.join(rag_db_path, file)
        if os.listdir(folder_path): # check if folder is non-empty
            return True
        
    return False


def load_rag(embedding_model, chroma_path, openai_api_key):
    """
    Loads the RAG database if it has been initialized before and is ready to use.

    Args:
    - embedding_model (str): Name of the embedding model to be used for loading embeddings.
    - chroma_path (str): Path where the Chroma database is stored.
    - openai_api_key (str): OpenAI API Key

    Returns:
    - tuple (bool, Chroma or None): 
        - rag_ready (bool): true if the RAG database was successfully loaded, false otherwise.
        - rag_db (Chroma or None): The loaded Chroma database object if successful, None if loading failed.

    """
    rag_ready = False
    valid_rag_db = is_valid_rag_db(chroma_path)

    if not valid_rag_db:
        logger.warning("RAG database is not valid. Not loading it. Please run 'python db_generation.py first.")
        rag_db = None
        return rag_ready, rag_db

    try:
        langchain_ef = OpenAIEmbeddings(openai_api_key=openai_api_key, model=embedding_model)
        rag_db = Chroma(persist_directory=chroma_path, embedding_function=langchain_ef, collection_name="ipcc_collection")
        logger.info(f"RAG database loaded with {rag_db._collection.count()} documents.")
        rag_ready = True
    except Exception as e:
        logger.warning(f"Failed to load the RAG database: {e}")
        rag_db = None
        rag_ready = False

    return rag_ready, rag_db


def format_docs(docs):
    """
    Formats the retrieved documents into a single string.

    Params:
    docs (list): List of documents retrieved by the RAG database.

    Returns:
    str: Formatted string of the document contents.
    """
    return "\n\n".join(doc.page_content for doc in docs)


def query_rag(input_params, config, openai_api_key, rag_ready, rag_db):
    """
    Queries the RAG database with the user's input.

    Args:
    - input_params (dict): The user's input parameters.
    - config (dict): Configuration dictionary.
    - openai_api_key (str): OpenAI API Key.
    - rag_ready (bool): Boolean flag indicating whether the RAG database is loaded and ready.
    - rag_db (Chroma or None): The loaded RAG database object.

    Returns:
    - str or None: The response from the RAG query, or None if the query fails.
    """
    if not rag_ready:
        logger.warning("RAG database is not ready or loaded. Skipping RAG query.")
        return None
    try:
        retriever = rag_db.as_retriever()
        if retriever is None:
            logger.error("Failed to create retriever: retriever is None.")

        # load template from config
        template = config['rag_template']
        custom_rag_prompt = PromptTemplate.from_template(template)

        location = input_params['location_str']

        def get_loci(_):
            return location

        # inspect chain - just for development
        def inspect(state):
            """Print the state passed between Runnables in a langchain and pass it on"""
            logger.info(state)
            return state
        rag_chain = (
            {"context": retriever | format_docs, "location": RunnableLambda(get_loci), "question": RunnablePassthrough()}
            | RunnableLambda(inspect)
            | custom_rag_prompt
            | ChatOpenAI(model=config['model_name'], api_key=openai_api_key)
            | StrOutputParser()
        )
        rag_response = rag_chain.invoke(input_params['user_message'])
        logging.info(f"RAG response: {rag_response}")

        return rag_response

    except Exception as e:
        logger.error(f"Failed to perform RAG query: {e}")
        return None

--------------------------------------------------------------------------------
src/climsight/stream_handler.py
code
from langchain.callbacks.base import BaseCallbackHandler

class StreamHandler(BaseCallbackHandler):
    """
    Handles streaming output from LLM. Can work with both Streamlit and prompt-based applications.
    """

    def __init__(self, container=None, display_method="markdown"):
        self.container = container
        self.display_method = display_method
        self.text = ""

    def send_text(self, text: str) -> None:
        self.text += text
        self._display_text()        

    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self._display_text()

    def _display_text(self):
        if self.container:
            display_function = getattr(self.container, self.display_method, None)
            if display_function is not None:
                display_function(self.text)
            else:
                raise ValueError(f"Invalid display_method: {self.display_method}")

    def get_text(self):
        return self.text

--------------------------------------------------------------------------------
src/climsight/data_container.py
code
import pandas as pd
import xarray as xr
import matplotlib.pyplot as plt

class DataContainer:
    """
    A container class for managing data, figures, and datasets.

    Attributes:
    -----------
    df   : dict
        A dictionary to store pandas DataFrame to store tabular data.
    figs : dict
        A dictionary to store figures. example figs['haz_fig'] = {'fig':haz_fig,'source':source}
    data : dict
        A dictionary containing 'hist' and 'future' keys, each associated with an xarray Dataset.

    Methods:
    --------
    df:
        Property to get or set the DataFrame dictionary. Raises ValueError if the input is not a dictionary.
    figs:
        Property to get or set the figures dictionary. Raises ValueError if the input is not a dictionary.
    data:
        Property to get or set the data dictionary. Raises ValueError if the input is not a dictionary containing 'hist' and 'future' keys with xarray Datasets.
    """
    def __init__(self):
        self._df =   {}                  # Initialize as an empty dictionary for DataFrames
        self._figs = {}                  # Initialize as an empty dictionary for figures
        self._data = {}
        #{
        #    'hist': xr.Dataset(),        # Default to an empty xarray Dataset for historical data
        #    'future': xr.Dataset()       # Default to an empty xarray Dataset for future data
        #}

    @property
    def df(self):
        """Property to access the dictionary containing DataFrames."""
        return self._df

    @df.setter
    def df(self, value):
        """Set the DataFrame, must be a pandas DataFrame."""
        if isinstance(value, dict):
            self._df = value
        else:
            raise ValueError("df must be a dictionary of pandas DataFrame")

    @property
    def figs(self):
        """Property to access the figures dictionary."""
        return self._figs

    @figs.setter
    def figs(self, value):
        """Set the figures dictionary."""
        if isinstance(value, dict):
            self._figs = value
        else:
            raise ValueError("figs must be a dictionary")

    @property
    def data(self):
        """Property to access the data dictionary containing hist and future datasets."""
        return self._data

    @data.setter
    def data(self, value):
        if isinstance(value, dict):
            self._figs = value
        else:
            raise ValueError("data must be a dictionary")        
        #"""Set the data dictionary, must be a dictionary with 'hist' and 'future' as xarray Datasets."""
        #if isinstance(value, dict) and 'hist' in value and 'future' in value:
        #    if isinstance(value['hist'], xr.Dataset) and isinstance(value['future'], xr.Dataset):
        #        self._data = value
        #    else:
        #        raise ValueError("Both 'hist' and 'future' must be xarray Datasets")
        #else:
        #    raise ValueError("data must be a dictionary containing 'hist' and 'future' keys")

--------------------------------------------------------------------------------
src/climsight/climsight_classes.py
code
# climsight_classes.py

from pydantic import BaseModel
from typing import Sequence
from typing import Annotated
from langchain_core.messages import BaseMessage
import operator

class AgentState(BaseModel):
    messages: Annotated[Sequence[BaseMessage], operator.add]  # Not in use up to now
    user: str = ""  # User question
    next: str = ""  # List of next actions
    rag_agent_response: str = ""
    data_agent_response: dict = {}
    zero_agent_response: dict = {}
    final_answser: str = ""
    content_message: str = ""
    input_params: dict = {}
    smart_agent_response: dict = {}
    wikipedia_tool_response: str = ""
    # stream_handler: StreamHandler  # Uncomment if needed

--------------------------------------------------------------------------------
src/climsight/test_interfaces.py
code
from streamlit_interface import run_streamlit
from terminal_interface import run_terminal
import logging
import yaml
import os

#Initialize logging at the beginning of your main application
logger = logging.getLogger(__name__)
logging.basicConfig(
   filename='climsight.log',
   level=logging.INFO,
   format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
   datefmt='%Y-%m-%d %H:%M:%S'
)

skip_llm_call = True

config = {}
# Config
if not config:
   config_path = os.getenv('CONFIG_PATH', 'config.yml')
   logger.info(f"reading config from: {config_path}")
   try:
      with open(config_path, 'r') as file:
            config = yaml.safe_load(file)
   except Exception as e:
      logging.error(f"An error occurred while reading the file: {config_path}")
      raise RuntimeError(f"An error occurred while reading the file: {config_path}") from e
try:
   model_name = config['model_name']
   climatemodel_name = config['climatemodel_name']
   data_path = config['data_settings']['data_path']
   coastline_shapefile = config['coastline_shapefile']
   haz_path = config['haz_path']
   pop_path = config['pop_path']
   distance_from_event = config['distance_from_event']
   lat_default = config['lat_default']
   lon_default = config['lon_default']
   year_step = config['year_step']
   start_year = config['start_year']
   end_year = config['end_year']
   system_role = config['system_role']
except KeyError as e:
   logging.error(f"Missing configuration key: {e}")
   raise RuntimeError(f"Missing configuration key: {e}")



#run_streamlit(config, skip_llm_call=skip_llm_call)
run_terminal(config, skip_llm_call=skip_llm_call)
--------------------------------------------------------------------------------
src/climsight/terminal_interface.py
code
"""
    Terminal Wrapper Module 
"""
#general 
import logging
import yaml
import os
import matplotlib.pyplot as plt
import time

# rag
from rag import load_rag 

# climsight modules
from stream_handler import StreamHandler
from climsight_engine import llm_request, forming_request, location_request
from data_container import DataContainer

logger = logging.getLogger(__name__)

data_pocket = DataContainer()

def input_with_default(prompt, default_value):
    user_input = input(prompt)
    if user_input == "":
        return default_value
    return user_input

def print_verbose(verbose, message):
    if verbose:
        print(message)  

def run_terminal(config, api_key='', skip_llm_call=False, lon=None, lat=None, user_message='', show_add_info='',verbose=True, rag_activated=None, embedding_model='', chroma_path=''):
    '''
        Inputs:
        - config (dict): Configuration, default is an empty dictionary.   
        - api_key (string): API Key, default is an empty string. default ''
        - skip_llm_call (bool): If True - skipp final call to LLM. default False    
        - lat (float): Latitude of the location to analyze. default None
        - lon (float): Longitude of the location to analyze. default None
        - user_message (string): Question for the LLM. default empty ''
        - show_add_info (string): If 'y' - show additional information, if 'n' - do not show additional information. default ''
        - verbose (bool): If True - print additional information, if False - do not print additional information (used for loop request). default True
        - rag_activated (bool): whether or not to include the text based rag
        - embedding_model (str): embedding model to be used for loading the Chroma database.
        - chroma_path (str): Path where the Chroma database is stored.
        Output:
        - output (string): Output from the LLM.
    '''      
    # Config
    try:
        climatemodel_name = config['climatemodel_name']
        lat_default = config['lat_default']
        lon_default = config['lon_default']
        rag_default = config['rag_settings']['rag_activated']
    except KeyError as e:
        logging.error(f"Missing configuration key: {e}")
        raise RuntimeError(f"Missing configuration key: {e}")   

    if not isinstance(skip_llm_call, bool):
        logging.error(f"skip_llm_call must be bool")
        raise TypeError("skip_llm_call must be  bool")    

############################# input
    print_verbose(verbose, f"\n \n \n")
    print_verbose(verbose, f"Welcome to Climsight!")
    print_verbose(verbose, f"\n")    
    if lon is None:
        lon = input_with_default(f"Please provide longitude of the location ({lon_default}): ", lon_default)
        try:
            lon = float(lon)
        except Exception as e:
            logging.error(f"lat and lon must be floats: {e}")
            raise RuntimeError(f"lat and lon must be floats: {e}")            
    print_verbose(verbose, f"Longitude: {lon}")
    print_verbose(verbose, f"\n")        
    if lat is None:
        lat = input_with_default(f"Please provide latitude of the location ({lat_default}): ", lat_default)
        try:
            lat = float(lat)
        except Exception as e:
            logging.error(f"lat and lon must be floats: {e}")
            raise RuntimeError(f"lat and lon must be floats: {e}")
    print_verbose(verbose, f"Latitude: {lat}")
    print_verbose(verbose, f"\n")    

    if not isinstance(user_message, str):
        logging.error(f"user_message must be a string ")
        raise TypeError("user_message must be a string")
    
    if not user_message: 
        user_message = input(f"Describe the activity that you would like to evaluate:\n")
        print_verbose(verbose, f"\n")    

    if not isinstance(api_key, str):
        logging.error(f"api_key must be a string ")
        raise TypeError("api_key must be a string")
    if not api_key:
        api_key = os.environ.get("OPENAI_API_KEY") # check if OPENAI_API_KEY is set in the environment
    if (not api_key) and (not skip_llm_call):
        api_key = input("Please provide openAI API key: ")
        print_verbose(verbose, f"\n")    
    else:
        print_verbose(verbose, "openAI API key accepted.")
        print_verbose(verbose, f"\n")

    if rag_activated is None:
        rag_activated = input_with_default(f"Do you want to run ClimSight with (y) or without (n) additional text source RAG? (Default depends on your config settings): ", rag_default)
        if isinstance(rag_activated, str):
            if rag_activated == 'y':
                rag_activated = True
            elif rag_activated == 'n':
                rag_activated =  False
            else:
                logging.error("rag_activated must either be 'y', 'n', or empty, but nothing else")
                raise TypeError("Please enter either 'y', 'n', or leave it empty to use the default value.")
        if not isinstance(rag_activated, bool):
            logging.error('rag_activated must be a bool')
    print_verbose(verbose, f"RAG activated: {rag_activated}")
    print_verbose(verbose, f"\n")

    if not isinstance(show_add_info, str):
        logging.error(f"show_add_info must be a string ")
        raise TypeError("show_add_info must be a string")
    if not show_add_info:
        show_add_info = input_with_default("Do you want to see and save additional information? (y/n, default y): ","y")
    if show_add_info=="n":
        show_add_info=False
        print_verbose(verbose, f"Additional inforamtion will be not shown.")        
    else:
        show_add_info=True
        print_verbose(verbose, f"Additional inforamtion will be shown and saved in files.")                
    config['show_add_info'] = show_add_info
    
    print_verbose(verbose, "")
    print_verbose(verbose, "Getting info on a point...")
    
    # Record the start time
    start_time = time.time()

    # RAG
    if not skip_llm_call and rag_activated:
        try:
            logger.info("RAG is activated and skipllmcall is False. Loading RAG database...")
            rag_ready, rag_db = load_rag(embedding_model, chroma_path, api_key) # load the RAG database 
        except Exception as e:
            logger.warning(f"RAG database initialization skipped or failed: {e}")
            rag_ready = False
            rag_db = None
    
    is_on_land = True

    if config['llmModeKey'] == "direct_llm":
        generator = forming_request(config, lat, lon, user_message)
        while True:
            try:
                # Get the next intermediate result from the generator
                result = next(generator)
                print_verbose(verbose, f"{result}")
            except StopIteration as e:
                # The generator is exhausted, and e.value contains the final result
                gen_output = e.value
                # check if Error ocure:
                if isinstance(gen_output,str):
                    if "Error" in gen_output:
                        if "point_is_in_ocean" in gen_output:
                            is_on_land = False
                            print_verbose(verbose, f"The selected point is in the ocean. Please choose a location on land.")
                else:    
                    content_message, input_params, df_data, figs, data = e.value
                    data_pocket.df['df_data'] = df_data
                    data_pocket.figs = figs
                    data_pocket.data = data                
                break     
    else:
        # Agent LLM mode (load only location info)
        # get first location information only, input_params and content_message are only partly filled
        content_message, input_params = location_request(config, lat, lon)
        if not input_params:
            is_on_land = False
            print_verbose(verbose, f"The selected point is in the ocean. Please choose a location on land.")
        else:
            # extend input_params with user_message
            input_params['user_message'] = user_message
            content_message = "Human request: {user_message} \n " + content_message
            print_verbose(verbose, f"{input_params['location_str_for_print']}")
            if input_params['is_inland_water']:
                print_verbose(verbose, f"""{input_params['water_body_status']}: Our analyses are currently only meant for land areas. Please select another location for a better result.""")
    
    # Record the start time
    forming_request_time = time.time() - start_time
        
    if is_on_land:        
        start_time = time.time()
        stream_handler = StreamHandler()
        output = ''
        if not skip_llm_call:
            output = llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db, data_pocket)   
            figs = data_pocket.figs
            data = data_pocket.data
            df_data = data_pocket.df['df_data']            
                
            print_verbose(verbose, "|=============================================================================")    
            print_verbose(verbose, "")    
            print_verbose(verbose, output)            
            print_verbose(verbose, "")    
            print_verbose(verbose, "|=============================================================================")    
        else:
            output = content_message.format(**input_params)
            print_verbose(verbose, "|============================ Prompt after formatting:  ======================")    
            print_verbose(verbose, "")            
            print_verbose(verbose, config['system_role'])    
            print_verbose(verbose, "")            
            print_verbose(verbose, output)            
            print_verbose(verbose, )    
            print_verbose(verbose, "|=============================================================================")    
                
        # Record the time
        llm_request_time = time.time() - start_time

        # PLOTTING ADDITIONAL INFORMATION
        if show_add_info: 
            print_verbose(verbose, "Additional information")
            if 'lat' and 'lon' in input_params:
                print_verbose(verbose, f"**Coordinates:** {input_params['lat']}, {input_params['lon']}")
            if 'elevation' in input_params:
                print_verbose(verbose, f"**Elevation:** {input_params['elevation']} m")
            if 'current_land_use' in input_params:
                print_verbose(verbose, f"**Current land use:** {input_params['current_land_use']}")
            if 'soil' in input_params:
                print_verbose(verbose, f"**Soil type:** {input_params['soil']}")
            if 'biodiv' in input_params:
                print_verbose(verbose, f"**Occuring species:** {input_params['biodiv']}")
            if 'distance_to_coastline' in input_params:
                print_verbose(verbose, f"**Distance to the shore:** {round(float(input_params['distance_to_coastline']), 2)} m")
            # figures need to move to engine
            # Climate Data
            # print("**Climate data:**")
            # print(
            #     "Near surface temperature (in C)",
            # )
            # st.line_chart(
            #     df_data,
            #     x="Month",
            #     y=["Present Day Temperature", "Future Temperature"],
            #     color=["#d62728", "#0000ff"],
            # )
            # print(
            #     "Precipitation (in mm)",
            # )
            # st.line_chart(
            #     df_data,
            #     x="Month",
            #     y=["Present Day Precipitation", "Future Precipitation"],
            #     color=["#d62728", "#0000ff"],
            # )
            # print(
            #     "Wind speed (in m*s-1)",
            # )
            # st.line_chart(
            #     df_data,
            #     x="Month",
            #     y=["Present Day Wind Speed", "Future Wind Speed"],
            #     color=["#d62728", "#0000ff"],
            # )
            # Determine the model information string based on climatemodel_name
            # if climatemodel_name == 'AWI_CM':
            #     model_info = 'AWI-CM-1-1-MR, scenarios: historical and SSP5-8.5'
            # elif climatemodel_name == 'tco1279':
            #     model_info = 'AWI-CM-3 TCo1279_DART, scenarios: historical (2000-2009) and SSP5-8.5 (2090-2099)'
            # elif climatemodel_name == 'tco319':
            #     model_info = 'AWI-CM-3 TCo319_DART, scenarios: historical (2000-2009), and SSP5-8.5 (2090-2099)'
            # else:
            #     model_info = 'unknown climate model'

            # print("Climate model: ")
            # print("   ", model_info)

            # Natural Hazards
            if 'haz_fig' in figs:
                fname = "natural_hazards.png"
                print_verbose(verbose, f"Figure with natural hazards was saved in {fname}.")
                figs['haz_fig']['fig'].savefig(fname)
                print_verbose(verbose, "Source for this figure: ")
                print_verbose(verbose, figs['haz_fig']['source'])
                print_verbose(verbose, "\n")    
            # Population Data
            if 'population_plot' in figs:
                fname = "population_data.png"            
                print_verbose(verbose, f"Figure with population data was saved in {fname}.")
                figs['population_plot']['fig'].savefig(fname)
                print_verbose(verbose, "Source for this figure: ")
                print_verbose(verbose, figs['population_plot']['source'])
                
    
        #print(f"Time for forming request: {forming_request_time}")
        #print(f"Time for LLM request: {llm_request_time}")
        
    return output
--------------------------------------------------------------------------------
src/climsight/climsight_engine.py
code
"""
Engine for Climsight: This module contains functions that combine environmental and 
climate data based on latitude and longitude. It constructs prompts for language 
learning model (LLM) queries and handles the interaction with the LLM to generate 
responses based on the input data.

The main inputs include latitude, longitude, and a user_message. Data such as historical 
and future data (from climate models) can be provided with pre_data. By default, 
pre_data is an empty dictionary, and data will be loaded anew each time.
The config parameter is a configuration dictionary; if not provided, it will be 
loaded again from a YAML file.

"""
import yaml
import os
import logging
# import classes for climsight
from stream_handler import StreamHandler
import pandas as pd
from data_container import DataContainer

# import langchain functions
# from langchain_community.chat_models import ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts.chat import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
# import components for used by agent
from pydantic import BaseModel
#from typing import Annotated
from typing import Sequence
#import operator
#from langchain_core.messages import BaseMessage
from langgraph.graph import END, StateGraph, START

# import RAG components
from langchain_chroma import Chroma
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_core.runnables import RunnableLambda
from langchain_openai import ChatOpenAI

from rag import query_rag
from typing import Optional, Literal, Union, List

# import climsight classes
from climsight_classes import AgentState

# import smart_agent
from smart_agent import smart_agent

# import climsight functions
from geo_functions import (
   get_location,
   where_is_point,
   get_adress_string,
   get_location_details,
   closest_shore_distance,
   get_elevation_from_api,
   fetch_land_use,
   get_soil_from_api,
   is_point_onland,
   is_point_in_inlandwater
 )
from environmental_functions import (
   fetch_biodiversity,
   load_nat_haz_data,
   filter_events_within_square,
   plot_disaster_counts
)

from climate_functions import (
   load_data,
   extract_climate_data
)
from economic_functions import (
   get_population,
   plot_population,
   x_year_mean_population   
)

logger = logging.getLogger(__name__)


def location_request(config, lat, lon):
    content_message = None
    input_params = None 

    # ----- Check input types ------------
    if not isinstance(lat, float) or not isinstance(lon, float):
        logging.error(f"lat and lon must be floats in clim_request(...) ")
        raise TypeError("lat and lon must be floats")
    # Config
    try:
        natural_e_path = config['natural_e_path']
    except KeyError as e:
        logging.error(f"Missing configuration key: {e}")
        raise RuntimeError(f"Missing configuration key: {e}")
       
    ##  =================== prepare data ==================
    logger.debug(f"is_point_onland : {lat}, {lon}")        
    try:
        is_on_land, water_body_status = is_point_onland(lat, lon, natural_e_path)
    except Exception as e:
        logging.error(f"Unexpected error in is_point_onland: {e}")
        raise RuntimeError(f"Unexpected error in is_point_onland: {e}")

    ######################## Here is a critical point ######################
    
    if not is_on_land:
        return content_message, input_params
    ######################## Here is a critical point ######################
    ##  ===== location
    logger.debug(f"Retrieving location from: {lat}, {lon}")        
    try:
        location = get_location(lat, lon)
    except Exception as e:
        logging.error(f"Unexpected error in get_location: {e}")
        raise RuntimeError(f"Unexpected error in get_location: {e}")
    ##  == adress 
    logger.debug(f"get_adress_string from: {lat}, {lon}")        
    try:
        location_str, location_str_for_print, country = get_adress_string(location)
    except Exception as e:
        logging.error(f"Unexpected error in get_adress_string: {e}")
        raise RuntimeError(f"Unexpected error in get_adress_string: {e}")

    logger.debug(f"is_point_onland from: {lat}, {lon}")            
    try:
        is_inland_water, water_body_status = is_point_in_inlandwater(lat, lon)
    except Exception as e:
        logging.error(f"Unexpected error in where_is_point: {e}")
        raise RuntimeError(f"Unexpected error in where_is_point: {e}")

    ##  == location details
    logger.debug(f"get_location_details")            
    try:
        add_properties = get_location_details(location)
    except Exception as e:
        logging.error(f"Unexpected error in get_location_details: {e}")
        raise RuntimeError(f"Unexpected error in get_location_details: {e}")
    
    content_message = """
        Location: latitude = {lat}, longitude = {lon} \n
        Adress: {location_str} \n
        Where is this point?: {water_body_status} \n
        Additional location information: {add_properties} \n
        """        
    input_params = {
        "lat": str(lat),
        "lon": str(lon),
        "location_str": location_str,
        "water_body_status": water_body_status,
        "add_properties": add_properties,
        "location_str_for_print": location_str_for_print,
        "is_inland_water": is_inland_water,
        "country": country
    }         
    return content_message, input_params


def forming_request(config, lat, lon, user_message, data={}, show_add_info=True):
    '''
    Inputs:
    - config (dict): Configuration 
    - lat (float): Latitude of the location to analyze.
    - lon (float): Longitude of the location to analyze.
    - user_message (string): Question for the LLM.
    - data (dict): Preloaded data, default is an empty dictionary.
    - show_add_info (bool): add additional info, here plot fiugures
    be aware that data could be modified  by this function
    
    Outputs:
    - several yields 
    - final return: content_message, input_params, df_data, figs, data
    
    How to call it in wrapers (strealit, terminal, ... )
        logger = logging.getLogger(__name__)
        logging.basicConfig( ...
        lat, lon, user_message = ...
        stream_handler = StreamHandler(...)

        generator = clim_request(lat, lon, user_message, stream_handler)

        while True:
        try:
            # Get the next intermediate result from the generator
            result = next(generator)
            print(f"Intermediate result: {result}")
        except StopIteration as e:
            # The generator is exhausted, and e.value contains the final result
            final_result = e.value
            print(f"Final result: {final_result}")
            break
    '''
    
    # ----- Check input types ------------
    if not isinstance(lat, float) or not isinstance(lon, float):
        logging.error(f"lat and lon must be floats in clim_request(...) ")
        raise TypeError("lat and lon must be floats")
   
    if not isinstance(user_message, str):
        logging.error(f"user_message must be a string in clim_request(...) ")
        raise TypeError("user_message must be a string")

    # Config
    try:
        data_path = config['data_settings']['data_path']
        coastline_shapefile = config['coastline_shapefile']
        haz_path = config['haz_path']
        pop_path = config['pop_path']
        distance_from_event = config['distance_from_event']
        year_step = config['year_step']
        start_year = config['start_year']
        end_year = config['end_year']
        natural_e_path = config['natural_e_path']
    except KeyError as e:
        logging.error(f"Missing configuration key: {e}")
        raise RuntimeError(f"Missing configuration key: {e}")
        
    # data
    datakeys = list(data)
    if 'hist' and 'future' not in datakeys:
        logger.info(f"reading data from: {data_path}")        
        yield f"reading data"
        hist, future = load_data(config)
        data['hist'] = hist
        data['future'] = future
    else:
        logger.info(f"Data are preloaded in data dict")                
        hist, future = data['hist'], data['future']
        
    #content_message defined below now

    ##  =================== prepare data ==================
    logger.debug(f"is_point_onland : {lat}, {lon}")        
    try:
        is_on_land, water_body_status = is_point_onland(lat, lon, natural_e_path)
    except Exception as e:
        logging.error(f"Unexpected error in is_point_onland: {e}")
        raise RuntimeError(f"Unexpected error in is_point_onland: {e}")

    ######################## Here is a critical point ######################
    if not is_on_land:
        return "Error: point_is_in_ocean"
    ######################## Here is a critical point ######################
        
    ##  ===== location
    logger.debug(f"Retrieving location from: {lat}, {lon}")        
    try:
        location = get_location(lat, lon)
    except Exception as e:
        logging.error(f"Unexpected error in get_location: {e}")
        raise RuntimeError(f"Unexpected error in get_location: {e}")
    ##  == adress 
    logger.debug(f"get_adress_string from: {lat}, {lon}")        
    try:
        location_str, location_str_for_print, country = get_adress_string(location)
    except Exception as e:
        logging.error(f"Unexpected error in get_adress_string: {e}")
        raise RuntimeError(f"Unexpected error in get_adress_string: {e}")

    yield f"**Coordinates:** {round(lat, 4)}, {round(lon, 4)}"
    ##  == wet / dry
    # logger.debug(f"where_is_point from: {lat}, {lon}")            
    # try:
    #     is_on_land, in_lake, lake_name, near_river, river_name, water_body_status = where_is_point(lat, lon)
    # except Exception as e:
    #     logging.error(f"Unexpected error in where_is_point: {e}")
    #     raise RuntimeError(f"Unexpected error in where_is_point: {e}")
    logger.debug(f"is_point_onland from: {lat}, {lon}")            
    try:
        is_inland_water, water_body_status = is_point_in_inlandwater(lat, lon)
    except Exception as e:
        logging.error(f"Unexpected error in where_is_point: {e}")
        raise RuntimeError(f"Unexpected error in where_is_point: {e}")

    
    
    ##  == location details
    logger.debug(f"get_location_details")            
    try:
        add_properties = get_location_details(location)
    except Exception as e:
        logging.error(f"Unexpected error in get_location_details: {e}")
        raise RuntimeError(f"Unexpected error in get_location_details: {e}")
    
    #if is_on_land:  We already have return if is_on_land
    if not is_inland_water:
        yield f"{location_str_for_print}"            
        pass
    if is_inland_water:
        yield f"{water_body_status} Our analyses are currently only meant for land areas. Please select another location for a better result."
        #yield f"You have choose {'lake ' + lake_name if lake_name else 'a lake'}. Our analyses are currently only meant for land areas. Please select another location for a better result."
        logging.info(f"location in inland water: water_body_status= {water_body_status}")
            
        #if near_river:
        #    yield f"You have choose on a place that might be in {'the river ' + river_name if river_name else 'a river'}. Our analyses are currently only meant for land areas. Please select another location for a better result."              
        #    logging.info(f"location in {'the river ' + river_name if river_name else 'a river'}")            
    # else:
    #     yield f"You have selected a place somewhere in the ocean. Our analyses are currently only meant for land areas. Please select another location for a better result."
    #     logging.info(f"place somewhere in the ocean")
    #     country = None
    #     location_str = None
    #     add_properties = None
    ##  == elevation
    logger.debug(f"get_elevation_from_api from: {lat}, {lon}")        
    try:
        elevation = get_elevation_from_api(lat, lon)
    except Exception as e:
        elevation = "Not known"
        logging.exception(f"elevation = Not known: {e}")
    ##  == land use        
    logger.debug(f"fetch_land_use from: {lat}, {lon}")        
    try:
        land_use_data = fetch_land_use(lon, lat)
    except Exception as e:
        land_use_data = "Not known"
        logging.exception(f"land_use_data = Not known: {e}")

    logger.debug(f"get current_land_use from land_use_data")              
    try:
        current_land_use = land_use_data["elements"][0]["tags"]["landuse"]
    except Exception as e:
        current_land_use = "Not known"
        logging.exception(f"{e}. Continue with: current_land_use = Not known")
    ##  == soil
    logger.debug(f"get current_land_use from land_use_data")              
    try:
        soil = get_soil_from_api(lat, lon)
    except Exception as e:
        soil = "Not known"
        logging.exception(f"soil = Not known: {e}")
    ##  == biodiversity
    logger.debug(f"fetch_biodiversity from: {round(lat), round(lon)}")              
    try:
        biodiv = fetch_biodiversity(round(lat), round(lon))
    except Exception as e:
        biodiv = "Not known"
        logging.error(f"Unexpected error in fetch_biodiversity: {e}")
    ##  == coast distance
    logger.debug(f"closest_shore_distance from: {lat, lon}")              
    try:
        distance_to_coastline = closest_shore_distance(lat, lon, coastline_shapefile)
    except Exception as e:
        distance_to_coastline = "Not known"
        logging.error(f"Unexpected error in closest_shore_distance: {e}")

    ##  =================== climate data 
    ## == create pandas dataframe
    logger.debug(f"extract_climate_data for: {lat, lon}")              
    try:
        df_data, data_dict = extract_climate_data(lat, lon, hist, future, config)
    except Exception as e:
        logging.error(f"Unexpected error in extract_climate_data: {e}")
        raise RuntimeError(f"Unexpected error in extract_climate_data: {e}")
    ## == hazards
    logger.debug(f"filter_events_within_square for: {lat, lon}")              
    try:
        filtered_events_square, promt_hazard_data = filter_events_within_square(lat, lon, haz_path, distance_from_event)
    except Exception as e:
        logging.error(f"Unexpected error in filter_events_within_square: {e}")
        raise RuntimeError(f"Unexpected error in filter_events_within_square: {e}")
    ## == population
    logger.debug(f"x_year_mean_population for: {pop_path, country}")              
    try:
        population = x_year_mean_population(pop_path, country, year_step=year_step, start_year=start_year, end_year=end_year)
    except Exception as e:
        logging.error(f"Unexpected error in filter_events_within_square: {e}")
        raise RuntimeError(f"Unexpected error in filter_events_within_square: {e}")

    ##  ===================  plotting      =========================   
    if show_add_info:
        figs = {}
        
        logger.debug(f"plot_disaster_counts for filtered_events_square")              
        try:
            haz_fig = plot_disaster_counts(filtered_events_square)
            source = '''
                        *The GDIS data descriptor*  
                        Rosvold, E.L., Buhaug, H. GDIS, a global dataset of geocoded disaster locations. Sci Data 8,
                        61 (2021). https://doi.org/10.1038/s41597-021-00846-6  
                        *The GDIS dataset*  
                        Rosvold, E. and H. Buhaug. 2021. Geocoded disaster (GDIS) dataset. Palisades, NY: NASA
                        Socioeconomic Data and Applications Center (SEDAC). https://doi.org/10.7927/zz3b-8y61.
                        Accessed DAY MONTH YEAR.  
                        *The EM-DAT dataset*  
                        Guha-Sapir, Debarati, Below, Regina, & Hoyois, Philippe (2014). EM-DAT: International
                        disaster database. Centre for Research on the Epidemiology of Disasters (CRED).
                    '''
            if not (haz_fig is None):
                figs['haz_fig'] = {'fig':haz_fig,'source':source}
        except Exception as e:
            logging.error(f"Unexpected error in plot_disaster_counts: {e}")
            raise RuntimeError(f"Unexpected error in plot_disaster_counts: {e}")

        logger.debug(f"plot_population for: {pop_path, country}")              
        try:
            population_plot = plot_population(pop_path, country)
            source = '''
                    United Nations, Department of Economic and Social Affairs, Population Division (2022). World Population Prospects 2022, Online Edition. 
                    Accessible at: https://population.un.org/wpp/Download/Standard/CSV/.
                    '''
            if not (population_plot is None):
                figs['population_plot'] = {'fig':population_plot,'source':source}        
        except Exception as e:
            logging.error(f"Unexpected error in population_plot: {e}")
            raise RuntimeError(f"Unexpected error in population_plot: {e}")       
        
        

    ## == policy IS NOT IN USE
    policy = ""
    
    content_message = """{user_message} \n \
        Location: latitude = {lat}, longitude = {lon} \n
        Adress: {location_str} \n
        Where is this point?: {water_body_status} \n
        Policy: {policy} \n
        Additional location information: {add_properties} \n
        Distance to the closest coastline: {distance_to_coastline} \n
        Elevation above sea level: {elevation} \n
        Current landuse: {current_land_use} \n
        Current soil type: {soil} \n
        Occuring species: {biodiv} \n
        Current mean monthly temperature for each month: {hist_temp_str} \n
        Future monthly temperatures for each month at the location: {future_temp_str}\n
        Current precipitation flux (mm/month): {hist_pr_str} \n
        Future precipitation flux (mm/month): {future_pr_str} \n
        Current u wind component (in m/s): {hist_uas_str} \n
        Future u wind component (in m/s): {future_uas_str} \n
        Current v wind component (in m/s): {hist_vas_str} \n
        Future v wind component (in m/s): {future_vas_str} \n
        Natural hazards: {nat_hazards} \n
        Population data: {population} \n
        """        
    input_params = {
        "user_message": user_message,
        "lat": str(lat),
        "lon": str(lon),
        "location_str": location_str,
        "water_body_status": water_body_status,
        "add_properties": add_properties,
        "policy": policy,
        "distance_to_coastline": str(distance_to_coastline),
        "elevation": str(elevation),
        "current_land_use": current_land_use,
        "soil": soil,
        "biodiv": biodiv,
        "hist_temp_str": data_dict["hist_Temperature"],
        "future_temp_str": data_dict["future_Temperature"],
        "hist_pr_str": data_dict["hist_Precipitation"],
        "future_pr_str": data_dict["future_Precipitation"],
        "hist_uas_str": data_dict["hist_u_wind"],
        "future_uas_str": data_dict["future_u_wind"],
        "hist_vas_str": data_dict["hist_v_wind"],
        "future_vas_str": data_dict["future_v_wind"],
        "nat_hazards": promt_hazard_data,
        "population": population,
    }               
    return content_message, input_params, df_data, figs, data

def llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db, data_pocket):
    """
    Handles LLM requests based on the mode specified in the configuration.

    Parameters:
    - content_message (str): The message content for the LLM.
    - input_params (dict): Input parameters for the LLM request.
    - config (dict): Configuration settings, including 'llmModeKey'.
    - api_key (str): API key for the LLM service.
    - stream_handler (StreamHandler): An instance of the StreamHandler class, used for streaming responses from the LLM.
    - rag_ready (bool): A flag indicating whether the RAG database is ready and available for queries.
    - rag_db (Chroma or None): The loaded RAG database object, used to retrieve relevant documents for the LLM prompt.    

    Returns:
    output (any): The output from the LLM request.

    Raises:
    TypeError: If 'llmModeKey' in the config is not recognized.
    """
    if config['llmModeKey'] == "direct_llm":
        output = direct_llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db)
    elif config['llmModeKey'] == "agent_llm":
        output = agent_llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db, data_pocket)
    else:
        logging.error(f"Wrong llmModeKey in config file: {config['llmModeKey']}")
        raise TypeError(f"Wrong llmModeKey in config file: {config['llmModeKey']}")
    return output

def direct_llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db):
    """
    Sends a request to the LLM with optional RAG integration and returns the generated response.

    Args:
    - content_message (str): The message or prompt to be sent to the LLM.
    - input_params (dict): A dictionary of input parameters for the LLM, including information such as latitude, longitude, and other context.
    - config (dict): Configuration settings for the LLM and RAG.
    - api_key (str): The OpenAI API key used to authenticate the LLM request.
    - stream_handler (StreamHandler): An instance of the StreamHandler class, used for streaming responses from the LLM.
    - rag_ready (bool): A flag indicating whether the RAG database is ready and available for queries.
    - rag_db (Chroma or None): The loaded RAG database object, used to retrieve relevant documents for the LLM prompt.

    Returns:
    - str: The response generated by the LLM based on the input message and parameters.
    """

    if not isinstance(stream_handler, StreamHandler):
        logging.error(f"stream_handler must be an instance of StreamHandler")
        raise TypeError("stream_handler must be an instance of StreamHandler")    
    
    ##  ===================  start with LLM =========================
    logging.info(f"Generating...")    

    ## === RAG integration === ##
    rag_response = query_rag(input_params, config, api_key, rag_ready, rag_db)
    # Check if rag_response is valid and not the string "None"
    if rag_response and rag_response != "None":
        content_message += f"\n        RAG(text) response: {rag_response}"
        input_params['rag_response'] = rag_response
    else:
        # Log the absence of a valid RAG response
        logger.info("RAG response is None. Proceeding without RAG context.")

    logger.debug(f"start ChatOpenAI, LLMChain ")                 
    llm = ChatOpenAI(
        openai_api_key=api_key,
        model_name=config['model_name'],
        streaming=True,
        callbacks=[stream_handler],
    )
    system_message_prompt = SystemMessagePromptTemplate.from_template(config['system_role'])
    human_message_prompt = HumanMessagePromptTemplate.from_template(content_message)
    chat_prompt = ChatPromptTemplate.from_messages(
        [system_message_prompt, human_message_prompt]
    )
    chain = LLMChain(
        llm=llm,
        prompt=chat_prompt,
        output_key="review",
        verbose=True,
    )

    logger.info("Calling LLM with configured chain.")
    logger.debug(f"call  LLM, chain.run ")                 
    # Pass the input_params dictionary to chain.run() using the ** operator
    output = chain.run(**input_params, verbose=True)
    logger.info("LLM request completed successfully.")

    return output

def agent_llm_request(content_message, input_params, config, api_key, stream_handler, rag_ready, rag_db, data_pocket):
    # function similar to llm_request but with agent structure
    # agent is consist of supervisor and nod that is responsible to call RAG
    # supervisor need to decide if call RAG or not

    if not isinstance(stream_handler, StreamHandler):
        logging.error(f"stream_handler must be an instance of StreamHandler")
        raise TypeError("stream_handler must be an instance of StreamHandler")
    
    lat = float(input_params['lat']) # should be already present in input_params
    lon = float(input_params['lon']) # should be already present in input_params
    
    logger.info(f"start agent_request")
    
    llm_agent = ChatOpenAI(
        openai_api_key=api_key,
        model_name=config['model_name'],
    )
        # streaming=True,
        # callbacks=[stream_handler],    
    '''
    class AgentState(BaseModel):
        messages: Annotated[Sequence[BaseMessage], operator.add]  #not in use up to now
        user: str = "" #user question
        next: str = "" #list of next actions
        rag_agent_response: str = ""
        data_agent_response: dict = {}
        zero_agent_response: dict = {}
        final_answser: str = ""
        content_message: str = ""
        input_params: dict = {}
        smart_agent_response: dict = {}
        # stream_handler: StreamHandler
    '''
               
    def zero_rag_agent(state: AgentState, figs = {}):
      
        logger.debug(f"get_elevation_from_api from: {lat}, {lon}")        
        try:
            elevation = get_elevation_from_api(lat, lon)
        except Exception as e:
            elevation = None
            logging.exception(f"elevation = Not known: {e}")
        ##  == land use        
        logger.debug(f"fetch_land_use from: {lat}, {lon}")        
        try:
            land_use_data = fetch_land_use(lon, lat)
        except Exception as e:
            land_use_data = None
            logging.exception(f"land_use_data = None: {e}")

        logger.debug(f"get current_land_use from land_use_data")              
        try:
            current_land_use = land_use_data["elements"][0]["tags"]["landuse"]
        except Exception as e:
            current_land_use = None
            logging.exception(f"{e}. Continue with: current_land_use = None")
        ##  == soil
        logger.debug(f"get current_land_use from land_use_data")              
        try:
            soil = get_soil_from_api(lat, lon)
        except Exception as e:
            soil = None
            logging.exception(f"soil = None: {e}")
        ##  == biodiversity
        logger.debug(f"fetch_biodiversity from: {round(lat), round(lon)}")              
        try:
            biodiv = fetch_biodiversity(round(lat), round(lon))
        except Exception as e:
            biodiv = None
            logging.error(f"Unexpected error in fetch_biodiversity: {e}")
        ##  == coast distance
        logger.debug(f"closest_shore_distance from: {lat, lon}")              
        try:
            distance_to_coastline = closest_shore_distance(lat, lon, config['coastline_shapefile'])
        except Exception as e:
            distance_to_coastline = None
            logging.error(f"Unexpected error in closest_shore_distance: {e}")

        ## == hazards
        logger.debug(f"filter_events_within_square for: {lat, lon}")              
        try:
            filtered_events_square, promt_hazard_data = filter_events_within_square(lat, lon, config['haz_path'], config['distance_from_event'])
        except Exception as e:
            promt_hazard_data = None
            filtered_events_square = None
            logging.error(f"Unexpected error in filter_events_within_square: {e}")
            raise RuntimeError(f"Unexpected error in filter_events_within_square: {e}")
              ## !!!!!!!!! raise should be changed to logging (add exceptions for ploting below)  
        ## == population
        logger.debug(f"x_year_mean_population for: {config['pop_path'], state.input_params['country']}")              
        try:
            population = x_year_mean_population(config['pop_path'], state.input_params['country'], 
                                                year_step=config['year_step'], start_year=config['start_year'], end_year=config['end_year'])
        except Exception as e:
            population = None
            logging.error(f"Unexpected error in filter_events_within_square: {e}")
            raise RuntimeError(f"Unexpected error in filter_events_within_square: {e}")
            ## !!!!!!!!! raise should be changed to logging (add exceptions for ploting below)  

        
        zero_agent_response = {}
        zero_agent_response['input_params'] = {}
        zero_agent_response['content_message'] = ""
        if elevation:
            zero_agent_response['input_params']['elevation'] = str(elevation)
            zero_agent_response['content_message'] += "Elevation above sea level: {elevation} \n"
        if current_land_use:
            zero_agent_response['input_params']['current_land_use'] = current_land_use
            zero_agent_response['content_message'] += "Current landuse: {current_land_use} \n"  
        if soil:
            zero_agent_response['input_params']['soil'] = soil
            zero_agent_response['content_message'] += "Current soil type: {soil} \n"        
        if biodiv:
            zero_agent_response['input_params']['biodiv'] = biodiv
            zero_agent_response['content_message'] += "Occuring species: {biodiv} \n"                    
        if distance_to_coastline:
            zero_agent_response['input_params']['distance_to_coastline'] = str(distance_to_coastline)
            zero_agent_response['content_message'] += "Distance to the closest coastline: {distance_to_coastline} \n"     
        if promt_hazard_data is not None:
            zero_agent_response['input_params']['nat_hazards'] = promt_hazard_data
            zero_agent_response['content_message'] += "Natural hazards: {nat_hazards} \n"    
        if population is not None:
            zero_agent_response['input_params']['population'] = population
            zero_agent_response['content_message'] += "Population data: {population} \n"                               

        ##  ===================  plotting      =========================   
        if config['show_add_info']:
            logger.debug(f"plot_disaster_counts for filtered_events_square")              
            try:
                haz_fig = plot_disaster_counts(filtered_events_square)
                source = '''
                            *The GDIS data descriptor*  
                            Rosvold, E.L., Buhaug, H. GDIS, a global dataset of geocoded disaster locations. Sci Data 8,
                            61 (2021). https://doi.org/10.1038/s41597-021-00846-6  
                            *The GDIS dataset*  
                            Rosvold, E. and H. Buhaug. 2021. Geocoded disaster (GDIS) dataset. Palisades, NY: NASA
                            Socioeconomic Data and Applications Center (SEDAC). https://doi.org/10.7927/zz3b-8y61.
                            Accessed DAY MONTH YEAR.  
                            *The EM-DAT dataset*  
                            Guha-Sapir, Debarati, Below, Regina, & Hoyois, Philippe (2014). EM-DAT: International
                            disaster database. Centre for Research on the Epidemiology of Disasters (CRED).
                        '''
                if not (haz_fig is None):
                    figs['haz_fig'] = {'fig':haz_fig,'source':source}
            except Exception as e:
                logging.error(f"Unexpected error in plot_disaster_counts: {e}")
                raise RuntimeError(f"Unexpected error in plot_disaster_counts: {e}")

            logger.debug(f"plot_population for: {config['pop_path'], state.input_params['country'] }")              
            try:
                population_plot = plot_population(config['pop_path'], state.input_params['country'] )
                source = '''
                        United Nations, Department of Economic and Social Affairs, Population Division (2022). World Population Prospects 2022, Online Edition. 
                        Accessible at: https://population.un.org/wpp/Download/Standard/CSV/.
                        '''
                if not (population_plot is None):
                    figs['population_plot'] = {'fig':population_plot,'source':source}        
            except Exception as e:
                logging.error(f"Unexpected error in population_plot: {e}")
                raise RuntimeError(f"Unexpected error in population_plot: {e}")    
        
        return {'zero_agent_response': zero_agent_response}
                    
    def data_agent(state: AgentState, data={}, df={}):
        # data
        # config, lat, lon  -  from the outer function (agent_clim_request(config,...))
        datakeys = list(data)
        if 'hist' and 'future' not in datakeys:
            logger.info(f"reading data from: {config['data_settings']['data_path']}")        
            data['hist'], data['future'] = load_data(config)
        else:
            logger.info(f"Data are preloaded in data dict")                

        ## == create pandas dataframe
        logger.debug(f"extract_climate_data for: {lat, lon}")              
        try:
            df_data_local, data_dict = extract_climate_data(lat, lon, data['hist'], data['future'], config)
            df['df_data'] = df_data_local
        except Exception as e:
            logging.error(f"Unexpected error in extract_climate_data: {e}")
            raise RuntimeError(f"Unexpected error in extract_climate_data: {e}")        
        
        data_agent_response = {}
        data_agent_response['input_params'] = {}
        data_agent_response['content_message'] = ""

        data_agent_response['input_params']["hist_temp_str"]   = data_dict["hist_Temperature"],
        data_agent_response['input_params']["future_temp_str"] = data_dict["future_Temperature"],
        data_agent_response['input_params']["hist_pr_str"]     = data_dict["hist_Precipitation"],
        data_agent_response['input_params']["future_pr_str"]   = data_dict["future_Precipitation"],
        data_agent_response['input_params']["hist_uas_str"]    = data_dict["hist_u_wind"],
        data_agent_response['input_params']["future_uas_str"]  = data_dict["future_u_wind"],
        data_agent_response['input_params']["hist_vas_str"]    = data_dict["hist_v_wind"],
        data_agent_response['input_params']["future_vas_str"]  = data_dict["future_v_wind"],       
        data_agent_response['content_message'] += """\n
        Current mean monthly temperature for each month: {hist_temp_str} \n
        Future monthly temperatures for each month at the location: {future_temp_str}\n
        Current precipitation flux (mm/month): {hist_pr_str} \n
        Future precipitation flux (mm/month): {future_pr_str} \n
        Current u wind component (in m/s): {hist_uas_str} \n
        Future u wind component (in m/s): {future_uas_str} \n
        Current v wind component (in m/s): {hist_vas_str} \n
        Future v wind component (in m/s): {future_vas_str} \n """
        
        print(f"Data agent in work.")

        return {'data_agent_response': data_agent_response}

      
    def rag_agent(state: AgentState):
        ## === RAG integration === ##
        rag_response = query_rag(input_params, config, api_key, rag_ready, rag_db)
        print(f"Rag agent in work.")
        return {'rag_agent_response': rag_response}


################# start of intro_agent #############################
    def intro_agent(state: AgentState):
        intro_message = """ 
        You are the introductory interface for a system named ClimSight, designed to help individuals evaluate the impact of climate change
        on current decision-making (e.g., installing wind turbines, solar panels, constructing buildings, creating parking lots, 
        opening a shop, or purchasing cropland). ClimSight operates on a local scale, providing data-driven insights specific to particular
        locations and aiding in climate-informed decision-making.

        ClimSight answers questions regarding the impacts of climate change on planned activities,
        using high-resolution climate data combined with an LLM to deliver actionable, location-specific information.
        This approach supports local decisions effectively, removing scalability and expertise limitations.

        Your task is to assess the potential climate-related risks and/or benefits associated with the user's planned activities.
        Additionally, use information about the user's country to retrieve relevant policies and regulations regarding climate change,
        environmental usage, and the specific activity the user has requested.

        **What you should do now:**

        At this stage, perform a quick pre-analysis of the user's question and decide on one of the following actions:

        1. **FINISH:** If the question is unrelated to ClimSight's purpose or is a simple inquiry outside your primary objectives,
        you can choose to finish the conversation by selecting FINISH and providing a concise answer. Examples of unrelated or simple questions:
        - Hi
        - How are you?
        - Who are you?
        - Write an essay on the history of trains.
        - Translate some text for me.

        2. **CONTINUE:** For all other cases, if the question relates to climate or location, select CONTINUE to proceed,
        which will prompt other agents to address the user's question. Note that the specific location may not be mentioned in the user's initial question, 
        but it will be clarified by subsequent agents.

        Based on the conversation, decide on one of the following responses:
        - **FINISH**: Provide a final answer to end the conversation.
        - **CONTINUE**: Indicate that the process should proceed without a final answer at this stage.

        Given this guidance, respond with either "FINISH" and the final answer, or "continue."
        """        
        intro_options = ["FINISH", "continue"]
        intro_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", intro_message),
                ("user", "{user_text}"),
            ])
        class routeResponse(BaseModel):
            next: Literal["FINISH", "continue"]  # Accepts single value only
            final_answer: str = ""  
              
        chain = (
             intro_prompt
             | llm_agent.with_structured_output(routeResponse)
         )
        # Pass the dictionary to invoke
        input = {"user_text": state.user}
        response = chain.invoke(input)
        state.final_answser = response.final_answer
        state.next = response.next
        return state
    
    
################# end of intro_agent #############################
    def combine_agent(state: AgentState): 
        print('combine_agent in work')

        #add RAG response to content_message and input_params
        if state.rag_agent_response != "None" and state.rag_agent_response != "":
            state.content_message += "\n        RAG(text) response: {rag_response} "
            state.input_params['rag_response'] = state.rag_agent_response

        #add zero_agent response to content_message and input_params                    
        if state.zero_agent_response != {}:
            state.content_message += state.zero_agent_response['content_message']
            state.input_params.update(state.zero_agent_response['input_params'])    
        
        #add data_agent response to content_message and input_params                    
        if state.data_agent_response != {}:
            state.content_message += state.data_agent_response['content_message']
            state.input_params.update(state.data_agent_response['input_params']) 

        if state.smart_agent_response != {}:
            smart_analysis = state.smart_agent_response.get('output', '')
            state.input_params['smart_agent_analysis'] = smart_analysis
            state.content_message += "\n Smart Data Extractor Agent Analysis: {smart_agent_analysis} "

            # Add Wikipedia tool response
        if state.wikipedia_tool_response != {}:
            wiki_response = state.wikipedia_tool_response
            state.input_params['wikipedia_tool_response'] = wiki_response
            state.content_message += "\n Wikipedia Search Response: {wikipedia_tool_response} "
      
                   
        system_message_prompt = SystemMessagePromptTemplate.from_template(config['system_role'])
        human_message_prompt = HumanMessagePromptTemplate.from_template(state.content_message)
        chat_prompt = ChatPromptTemplate.from_messages(
            [system_message_prompt, human_message_prompt]
        )
        chain = (
            chat_prompt
            | llm_agent
        )
        output = chain.invoke(state.input_params)
        return {'final_answser': output.content}
    
    def route_fromintro(state: AgentState) -> Sequence[str]:
        output = []
        if "FINISH" in state.next:
            return "FINISH"
        else:
            output.append("rag_agent")
            output.append("data_agent")
            output.append("zero_rag_agent")
            output.append("smart_agent")
        return output

        
    workflow = StateGraph(AgentState)

    figs = data_pocket.figs
    data = data_pocket.data
    df = data_pocket.df
    
     # Add nodes to the graph
    workflow.add_node("intro_agent", intro_agent)
    workflow.add_node("rag_agent", rag_agent)
    workflow.add_node("data_agent", lambda s: data_agent(s, data, df))  # Pass `data` as argument
    workflow.add_node("zero_rag_agent", lambda s: zero_rag_agent(s, figs))  # Pass `figs` as argument    
    workflow.add_node("smart_agent", lambda s: smart_agent(s, config, api_key))
    workflow.add_node("combine_agent", combine_agent)   

    workflow.set_entry_point("intro_agent") # Set the entry point of the graph
    path_map = {'rag_agent':'rag_agent', 'data_agent':'data_agent','zero_rag_agent':'zero_rag_agent','smart_agent':'smart_agent','FINISH':END}
    workflow.add_conditional_edges("intro_agent", route_fromintro, path_map=path_map)
    workflow.add_edge("rag_agent", "combine_agent")
    workflow.add_edge("data_agent", "combine_agent")
    workflow.add_edge("zero_rag_agent", "combine_agent")
    workflow.add_edge("smart_agent", "combine_agent")
    workflow.add_edge("combine_agent", END)
    # Compile the graph
    app = workflow.compile()
    
    #from IPython.display import Image, display
    #graph_image_path = 'graph_image.png'  # Specify the desired path for the image
    #graph_img= app.get_graph().draw_mermaid_png()
    #with open(graph_image_path, 'wb') as f:
    #    f.write(graph_img)  # Write the image bytes to the file
    
    state = AgentState(messages=[], input_params=input_params, user=input_params['user_message'], content_message=content_message)
    
    output = app.invoke(state)
    stream_handler.send_text(output['final_answser'])
    
    input_params = state.input_params
    content_message = state.content_message
    
    return output['final_answser']

--------------------------------------------------------------------------------
